{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12489008,"sourceType":"datasetVersion","datasetId":7881066},{"sourceId":12489032,"sourceType":"datasetVersion","datasetId":7881083},{"sourceId":12489036,"sourceType":"datasetVersion","datasetId":7881086}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:14:47.807691Z","iopub.execute_input":"2025-07-17T15:14:47.807930Z","iopub.status.idle":"2025-07-17T15:14:48.085807Z","shell.execute_reply.started":"2025-07-17T15:14:47.807911Z","shell.execute_reply":"2025-07-17T15:14:48.085067Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/vlsp-restaurant/2-VLSP2018-SA-Restaurant-dev.csv\n/kaggle/input/vlsp-restaurant/1-VLSP2018-SA-Restaurant-train.csv\n/kaggle/input/vlsp-restaurant/3-VLSP2018-SA-Restaurant-test.csv\n/kaggle/input/vlsp-hotel/3-VLSP2018-SA-Hotel-test.csv\n/kaggle/input/vlsp-hotel/2-VLSP2018-SA-Hotel-dev.csv\n/kaggle/input/vlsp-hotel/1-VLSP2018-SA-Hotel-train.csv\n/kaggle/input/vrbp-data/full_data.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"vrbp = pd.read_csv(\"/kaggle/input/vrbp-data/full_data.csv\", encoding = \"UTF-8\")\nvrbp.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T16:12:03.593968Z","iopub.execute_input":"2025-07-16T16:12:03.594339Z","iopub.status.idle":"2025-07-16T16:12:03.767805Z","shell.execute_reply.started":"2025-07-16T16:12:03.594319Z","shell.execute_reply":"2025-07-16T16:12:03.767242Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                                data stayingpower   texture  \\\n0  C√¥ng d·ª•ng: t·ªët\\r\\nK·∫øt c·∫•u: ƒë·∫πp\\r\\nƒê·ªô b·ªÅn m√†u: ...     positive  positive   \n1  C√¥ng d·ª•ng: son m√¥i\\r\\nK·∫øt c·∫•u: kh√¥\\r\\nƒê·ªô b·ªÅn m...     positive  positive   \n2  Son m·ªãn, m√πi th∆°m nh·∫π, l√¢u tr√¥i.\\r\\nVideo+ h√¨n...     positive  positive   \n3  C√¥ng d·ª•ng: ƒë√°nh son\\r\\nK·∫øt c·∫•u: ƒê√≥ng g√≥i c·∫©n t...     positive       NaN   \n4  C√¥ng d·ª•ng: t·ªët\\r\\nK·∫øt c·∫•u: t·ªët\\r\\nƒê·ªô b·ªÅn m√†u: ...     positive  positive   \n\n      smell     price others   colour  shipping packing  \n0       NaN       NaN    NaN      NaN       NaN     NaN  \n1       NaN       NaN    NaN      NaN       NaN     NaN  \n2  positive       NaN    NaN      NaN       NaN     NaN  \n3       NaN  positive    NaN      NaN  negative     NaN  \n4       NaN       NaN    NaN  neutral       NaN     NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>data</th>\n      <th>stayingpower</th>\n      <th>texture</th>\n      <th>smell</th>\n      <th>price</th>\n      <th>others</th>\n      <th>colour</th>\n      <th>shipping</th>\n      <th>packing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>C√¥ng d·ª•ng: t·ªët\\r\\nK·∫øt c·∫•u: ƒë·∫πp\\r\\nƒê·ªô b·ªÅn m√†u: ...</td>\n      <td>positive</td>\n      <td>positive</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>C√¥ng d·ª•ng: son m√¥i\\r\\nK·∫øt c·∫•u: kh√¥\\r\\nƒê·ªô b·ªÅn m...</td>\n      <td>positive</td>\n      <td>positive</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Son m·ªãn, m√πi th∆°m nh·∫π, l√¢u tr√¥i.\\r\\nVideo+ h√¨n...</td>\n      <td>positive</td>\n      <td>positive</td>\n      <td>positive</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>C√¥ng d·ª•ng: ƒë√°nh son\\r\\nK·∫øt c·∫•u: ƒê√≥ng g√≥i c·∫©n t...</td>\n      <td>positive</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>positive</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>negative</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>C√¥ng d·ª•ng: t·ªët\\r\\nK·∫øt c·∫•u: t·ªët\\r\\nƒê·ªô b·ªÅn m√†u: ...</td>\n      <td>positive</td>\n      <td>positive</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>neutral</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\nclass ABSADataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length=128):  # Reduced default\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        encoding = self.tokenizer(\n            text, truncation=True, padding='max_length',\n            max_length=self.max_length, return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n        }\n\n# =============================================================================\n# üéØ SINGLE-TASK LEARNING (STL) MODEL\n# =============================================================================\nclass STLModel(nn.Module):\n    \"\"\"Single-Task Learning: M·ªôt model cho m·ªôt aspect duy nh·∫•t\"\"\"\n    \n    def __init__(self, model_name, num_classes, dropout_rate=0.3):\n        super(STLModel, self).__init__()\n        self.transformer = AutoModel.from_pretrained(model_name)\n        self.dropout = nn.Dropout(dropout_rate)\n        self.classifier = nn.Linear(self.transformer.config.hidden_size, num_classes)\n        \n    def forward(self, input_ids, attention_mask):\n        outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        output = self.dropout(pooled_output)\n        logits = self.classifier(output)\n        return logits\n\n# =============================================================================\n# ü§ù MULTI-TASK LEARNING (MTL) MODEL  \n# =============================================================================\nclass MTLModel(nn.Module):\n    \"\"\"Multi-Task Learning: M·ªôt model cho nhi·ªÅu aspects c√πng l√∫c\"\"\"\n    \n    def __init__(self, model_name, aspect_classes, dropout_rate=0.3):\n        super(MTLModel, self).__init__()\n        # Shared transformer encoder\n        self.transformer = AutoModel.from_pretrained(model_name)\n        self.dropout = nn.Dropout(dropout_rate)\n        \n        # Task-specific classifiers cho m·ªói aspect\n        self.classifiers = nn.ModuleDict()\n        for aspect, num_classes in aspect_classes.items():\n            self.classifiers[aspect] = nn.Linear(\n                self.transformer.config.hidden_size, num_classes\n            )\n    \n    def forward(self, input_ids, attention_mask):\n        # Shared feature extraction\n        outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n        shared_features = self.dropout(outputs.pooler_output)\n        \n        # Task-specific predictions\n        logits = {}\n        for aspect in self.classifiers:\n            logits[aspect] = self.classifiers[aspect](shared_features)\n        \n        return logits\n\nclass STL_vs_MTL_Comparison:\n    \"\"\"So s√°nh STL vs MTL tr√™n multi-domain ABSA\"\"\"\n    \n    def __init__(self, model_name=\"vinai/phobert-base\", batch_size=2, max_length=128, force_cpu=False):\n        self.model_name = model_name\n        self.batch_size = batch_size  # Reduced from 8 to 2\n        self.max_length = max_length  # Reduced from 256 to 128\n        \n        # Device selection with memory check\n        if force_cpu:\n            self.device = torch.device('cpu')\n            print(\"üñ•Ô∏è  Forcing CPU usage\")\n        else:\n            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        \n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        \n        print(f\"üöÄ STL vs MTL Comparison System\")\n        print(f\"üì± Device: {self.device}\")\n        print(f\"ü§ñ Model: {model_name}\")\n        print(f\"üîß Batch size: {batch_size}, Max length: {max_length}\")\n        \n        # Clear GPU cache if available\n        if torch.cuda.is_available() and not force_cpu:\n            torch.cuda.empty_cache()\n            total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n            print(f\"üíæ GPU Memory: {total_memory:.1f}GB total\")\n            \n            # Check available memory\n            available_memory = (torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated()) / 1e9\n            print(f\"üíæ Available GPU Memory: {available_memory:.1f}GB\")\n            \n            if available_memory < 2.0:  # Less than 2GB available\n                print(\"‚ö†Ô∏è  Low GPU memory detected. Consider using force_cpu=True\")\n        \n        # Storage\n        self.datasets = {}\n        self.stl_models = {}  # STL: M·ªôt model per aspect\n        self.mtl_models = {}  # MTL: M·ªôt model per domain v·ªõi nhi·ªÅu aspects\n        self.results = {'STL': {}, 'MTL': {}}\n    \n    def switch_to_cpu(self):\n        \"\"\"Switch to CPU mode if GPU runs out of memory\"\"\"\n        self.device = torch.device('cpu')\n        print(\"üîÑ Switched to CPU mode due to memory constraints\")\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n    \n    def clear_memory(self):\n        \"\"\"Clear GPU memory cache\"\"\"\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n    \n    def load_domain_data(self, domain_name, file_path_or_data):\n        \"\"\"Load d·ªØ li·ªáu cho m·ªôt domain\"\"\"\n        print(f\"\\nüìä Loading {domain_name} domain...\")\n        \n        if domain_name == 'cosmetic':\n            return self._load_cosmetic_data(file_path_or_data)\n        else:\n            return self._load_vlsp_data(file_path_or_data, domain_name)\n    \n    def _load_cosmetic_data(self, file_path):\n        \"\"\"Load cosmetic dataset\"\"\"\n        df = pd.read_csv(file_path, encoding='latin-1')\n        text_col = 'data'\n        aspects = [col for col in df.columns if col != 'data']\n        \n        df_clean = df.dropna(subset=[text_col])\n        aspect_counts = df_clean[aspects].notna().sum(axis=1)\n        df_clean = df_clean[aspect_counts > 0]\n        \n        domain_data = {}\n        for aspect in aspects:\n            aspect_df = df_clean.dropna(subset=[aspect])\n            if len(aspect_df) > 100:  # ƒê·ªß d·ªØ li·ªáu\n                X = aspect_df[text_col].values\n                y = aspect_df[aspect].values\n                \n                encoder = LabelEncoder()\n                y_encoded = encoder.fit_transform(y)\n                \n                # Check if each class has at least 2 samples\n                unique, counts = np.unique(y_encoded, return_counts=True)\n                min_class_count = np.min(counts)\n                \n                if len(encoder.classes_) >= 2 and min_class_count >= 2:\n                    domain_data[aspect] = {\n                        'X': X, 'y': y_encoded, \n                        'encoder': encoder, 'classes': encoder.classes_\n                    }\n                    print(f\"  ‚úÖ {aspect}: {len(X)} samples, {len(encoder.classes_)} classes, min_class={min_class_count}\")\n                else:\n                    print(f\"  ‚ùå {aspect}: Skipped (classes={len(encoder.classes_)}, min_class_count={min_class_count})\")\n        \n        self.datasets['cosmetic'] = domain_data\n        return domain_data\n    \n    def _load_vlsp_data(self, data_path, domain_name):\n        \"\"\"Load VLSP Hotel/Restaurant data\"\"\"\n        train_df = pd.read_csv(f\"{data_path}/1-VLSP2018-SA-{domain_name.title()}-train.csv\")\n        dev_df = pd.read_csv(f\"{data_path}/2-VLSP2018-SA-{domain_name.title()}-dev.csv\")\n        \n        full_df = pd.concat([train_df, dev_df], ignore_index=True)\n        text_col = 'Review'\n        aspect_cols = [col for col in full_df.columns if col != 'Review']\n        \n        domain_data = {}\n        for aspect in aspect_cols[:5]:  # Limit cho demo\n            aspect_mask = full_df[aspect] != 0\n            if aspect_mask.sum() > 100:\n                X = full_df[aspect_mask][text_col].values\n                y = full_df[aspect_mask][aspect].values\n                \n                unique_labels = sorted(np.unique(y))\n                label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n                y_encoded = np.array([label_mapping[label] for label in y])\n                \n                # Check if each class has at least 2 samples\n                unique, counts = np.unique(y_encoded, return_counts=True)\n                min_class_count = np.min(counts)\n                \n                if len(unique_labels) >= 2 and min_class_count >= 2:\n                    encoder = LabelEncoder()\n                    encoder.classes_ = np.array([f\"class_{i}\" for i in range(len(unique_labels))])\n                    \n                    domain_data[aspect] = {\n                        'X': X, 'y': y_encoded,\n                        'encoder': encoder, 'classes': encoder.classes_\n                    }\n                    print(f\"  ‚úÖ {aspect}: {len(X)} samples, {len(unique_labels)} classes, min_class={min_class_count}\")\n                else:\n                    print(f\"  ‚ùå {aspect}: Skipped (classes={len(unique_labels)}, min_class_count={min_class_count})\")\n        \n        self.datasets[domain_name] = domain_data\n        return domain_data\n    \n    # =========================================================================\n    # üéØ SINGLE-TASK LEARNING IMPLEMENTATION\n    # =========================================================================\n    def train_stl_models(self, domain_name, epochs=2):\n        \"\"\"Train STL: M·ªôt model ri√™ng cho m·ªói aspect\"\"\"\n        print(f\"\\nüéØ TRAINING STL MODELS for {domain_name.upper()}\")\n        print(\"=\" * 60)\n        \n        domain_data = self.datasets[domain_name]\n        stl_results = {}\n        \n        for aspect, data in domain_data.items():\n            print(f\"\\nüìà STL Training: {aspect}\")\n            \n            # Clear memory before training each model\n            self.clear_memory()\n            \n            X, y = data['X'], data['y']\n            num_classes = len(data['classes'])\n            \n            # Split data\n            # Check if all classes have at least 2 samples for stratification\n            unique, counts = np.unique(y, return_counts=True)\n            can_stratify = np.all(counts >= 2)\n            \n            if can_stratify:\n                X_train, X_val, y_train, y_val = train_test_split(\n                    X, y, test_size=0.2, random_state=42, stratify=y\n                )\n            else:\n                print(f\"    ‚ö†Ô∏è  Some classes have <2 samples, skipping stratification\")\n                X_train, X_val, y_train, y_val = train_test_split(\n                    X, y, test_size=0.2, random_state=42\n                )\n            \n            # Create datasets with optimized max_length\n            train_dataset = ABSADataset(X_train, y_train, self.tokenizer, self.max_length)\n            val_dataset = ABSADataset(X_val, y_val, self.tokenizer, self.max_length)\n            \n            train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n            val_loader = DataLoader(val_dataset, batch_size=self.batch_size)\n            \n            # Create STL model - M·ªñI ASPECT C√ì MODEL RI√äNG\n            model = STLModel(self.model_name, num_classes).to(self.device)\n            optimizer = optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n            criterion = nn.CrossEntropyLoss()\n            \n            # Gradient accumulation setup\n            accumulation_steps = 2  # Effective batch size = batch_size * accumulation_steps\n            \n            # Training loop\n            model.train()\n            for epoch in range(epochs):\n                total_loss = 0\n                optimizer.zero_grad()\n                \n                for batch_idx, batch in enumerate(tqdm(train_loader, desc=f\"STL Epoch {epoch+1}\")):\n                    input_ids = batch['input_ids'].to(self.device)\n                    attention_mask = batch['attention_mask'].to(self.device)\n                    labels = batch['labels'].to(self.device)\n                    \n                    logits = model(input_ids, attention_mask)\n                    loss = criterion(logits, labels)\n                    \n                    # Scale loss for gradient accumulation\n                    loss = loss / accumulation_steps\n                    loss.backward()\n                    \n                    # Update weights every accumulation_steps\n                    if (batch_idx + 1) % accumulation_steps == 0:\n                        optimizer.step()\n                        optimizer.zero_grad()\n                        \n                        # Clear cache periodically\n                        if (batch_idx + 1) % (accumulation_steps * 4) == 0:\n                            self.clear_memory()\n                    \n                    total_loss += loss.item() * accumulation_steps\n                    \n                    # Delete batch tensors to free memory\n                    del input_ids, attention_mask, labels, logits, loss\n                \n                # Final optimizer step if there are remaining gradients\n                optimizer.step()\n                optimizer.zero_grad()\n                self.clear_memory()\n                \n                print(f\"    Epoch {epoch+1} Average Loss: {total_loss/len(train_loader):.4f}\")\n            \n            # Evaluation\n            model.eval()\n            all_preds, all_labels = [], []\n            with torch.no_grad():\n                for batch in val_loader:\n                    input_ids = batch['input_ids'].to(self.device)\n                    attention_mask = batch['attention_mask'].to(self.device)\n                    labels = batch['labels'].to(self.device)\n                    \n                    logits = model(input_ids, attention_mask)\n                    preds = torch.argmax(logits, dim=1)\n                    \n                    all_preds.extend(preds.cpu().numpy())\n                    all_labels.extend(labels.cpu().numpy())\n                    \n                    # Clear batch tensors\n                    del input_ids, attention_mask, labels, logits, preds\n            \n            self.clear_memory()\n            \n            accuracy = accuracy_score(all_labels, all_preds)\n            f1 = f1_score(all_labels, all_preds, average='weighted')\n            \n            print(f\"  ‚úÖ STL {aspect}: Accuracy={accuracy:.3f}, F1={f1:.3f}\")\n            \n            # Store results and move model to CPU to save GPU memory\n            model_cpu = model.cpu()\n            self.stl_models[f\"{domain_name}_{aspect}\"] = model_cpu\n            stl_results[aspect] = {'accuracy': accuracy, 'f1_score': f1}\n            \n            # Clear GPU memory\n            del model\n            self.clear_memory()\n        \n        self.results['STL'][domain_name] = stl_results\n        return stl_results\n    \n    # =========================================================================\n    # ü§ù MULTI-TASK LEARNING IMPLEMENTATION  \n    # =========================================================================\n    def train_mtl_model(self, domain_name, epochs=2):\n        \"\"\"Train MTL: M·ªôt model cho t·∫•t c·∫£ aspects trong domain\"\"\"\n        print(f\"\\nü§ù TRAINING MTL MODEL for {domain_name.upper()}\")\n        print(\"=\" * 60)\n        \n        # Clear memory before training\n        self.clear_memory()\n        \n        domain_data = self.datasets[domain_name]\n        \n        # Prepare MTL data - T·∫§T C·∫¢ ASPECTS C√ôNG L√öC\n        all_texts = []\n        all_labels = {}\n        aspect_classes = {}\n        \n        # Get all unique texts\n        unique_texts = set()\n        for aspect, data in domain_data.items():\n            unique_texts.update(data['X'])\n        \n        all_texts = list(unique_texts)\n        \n        # Create labels for each aspect\n        for aspect, data in domain_data.items():\n            aspect_classes[aspect] = len(data['classes'])\n            \n            # Map texts to labels\n            text_to_label = dict(zip(data['X'], data['y']))\n            labels = []\n            for text in all_texts:\n                if text in text_to_label:\n                    labels.append(text_to_label[text])\n                else:\n                    labels.append(-1)  # No label cho aspect n√†y\n            \n            all_labels[aspect] = np.array(labels)\n        \n        print(f\"  üìä MTL Training: {len(all_texts)} samples, {len(aspect_classes)} aspects\")\n        \n        # Split data\n        indices = np.arange(len(all_texts))\n        train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n        \n        # Create MTL model - M·ªòT MODEL CHO T·∫§T C·∫¢ ASPECTS\n        model = MTLModel(self.model_name, aspect_classes).to(self.device)\n        optimizer = optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n        criterion = nn.CrossEntropyLoss(ignore_index=-1)  # Ignore missing labels\n        \n        # Gradient accumulation setup\n        accumulation_steps = 2\n        \n        # Training loop\n        model.train()\n        for epoch in range(epochs):\n            total_loss = 0\n            num_batches = 0\n            optimizer.zero_grad()\n            \n            batch_count = 0\n            for i in tqdm(range(0, len(train_idx), self.batch_size), desc=f\"MTL Epoch {epoch+1}\"):\n                batch_indices = train_idx[i:i+self.batch_size]\n                batch_texts = [all_texts[idx] for idx in batch_indices]\n                \n                # Tokenize batch\n                encoding = self.tokenizer(\n                    batch_texts, truncation=True, padding='max_length',\n                    max_length=self.max_length, return_tensors='pt'\n                )\n                \n                input_ids = encoding['input_ids'].to(self.device)\n                attention_mask = encoding['attention_mask'].to(self.device)\n                \n                # Forward pass\n                logits = model(input_ids, attention_mask)\n                \n                # Calculate loss cho t·∫•t c·∫£ aspects\n                total_batch_loss = 0\n                batch_labels_list = []  # Store all batch_labels for deletion\n                \n                for aspect in aspect_classes:\n                    batch_labels = torch.tensor(\n                        all_labels[aspect][batch_indices], dtype=torch.long\n                    ).to(self.device)\n                    batch_labels_list.append(batch_labels)\n                    \n                    aspect_loss = criterion(logits[aspect], batch_labels)\n                    total_batch_loss += aspect_loss\n                \n                # Scale loss for gradient accumulation\n                total_batch_loss = total_batch_loss / accumulation_steps\n                total_batch_loss.backward()\n                \n                batch_count += 1\n                \n                # Update weights every accumulation_steps\n                if batch_count % accumulation_steps == 0:\n                    optimizer.step()\n                    optimizer.zero_grad()\n                    \n                    # Clear cache periodically\n                    if batch_count % (accumulation_steps * 4) == 0:\n                        self.clear_memory()\n                \n                total_loss += total_batch_loss.item() * accumulation_steps\n                num_batches += 1\n                \n                # Delete batch tensors to free memory\n                del input_ids, attention_mask, logits, total_batch_loss, encoding\n                for batch_labels in batch_labels_list:\n                    del batch_labels\n                del batch_labels_list\n            \n            # Final optimizer step\n            optimizer.step()\n            optimizer.zero_grad()\n            self.clear_memory()\n            \n            print(f\"    Epoch {epoch+1} Average Loss: {total_loss/num_batches:.4f}\")\n        \n        # Evaluation\n        model.eval()\n        mtl_results = {}\n        \n        for aspect in aspect_classes:\n            all_preds, all_labels_aspect = [], []\n            \n            with torch.no_grad():\n                for i in range(0, len(val_idx), self.batch_size):\n                    batch_indices = val_idx[i:i+self.batch_size]\n                    batch_texts = [all_texts[idx] for idx in batch_indices]\n                    \n                    encoding = self.tokenizer(\n                        batch_texts, truncation=True, padding='max_length',\n                        max_length=self.max_length, return_tensors='pt'\n                    )\n                    \n                    input_ids = encoding['input_ids'].to(self.device)\n                    attention_mask = encoding['attention_mask'].to(self.device)\n                    \n                    logits = model(input_ids, attention_mask)\n                    preds = torch.argmax(logits[aspect], dim=1)\n                    \n                    all_preds.extend(preds.cpu().numpy())\n                    all_labels_aspect.extend(all_labels[aspect][batch_indices])\n                    \n                    # Clear batch tensors\n                    del input_ids, attention_mask, logits, preds, encoding\n            \n            # Filter valid labels\n            valid_mask = np.array(all_labels_aspect) != -1\n            if valid_mask.sum() > 0:\n                valid_preds = np.array(all_preds)[valid_mask]\n                valid_labels = np.array(all_labels_aspect)[valid_mask]\n                \n                accuracy = accuracy_score(valid_labels, valid_preds)\n                f1 = f1_score(valid_labels, valid_preds, average='weighted')\n                \n                print(f\"  ‚úÖ MTL {aspect}: Accuracy={accuracy:.3f}, F1={f1:.3f}\")\n                mtl_results[aspect] = {'accuracy': accuracy, 'f1_score': f1}\n        \n        # Move model to CPU to save GPU memory\n        model_cpu = model.cpu()\n        self.mtl_models[domain_name] = model_cpu\n        self.results['MTL'][domain_name] = mtl_results\n        \n        # Clear GPU memory\n        del model\n        self.clear_memory()\n        \n        return mtl_results\n    \n    def comprehensive_comparison(self):\n        \"\"\"So s√°nh t·ªïng th·ªÉ STL vs MTL\"\"\"\n        print(\"\\n\" + \"=\"*80)\n        print(\"üìä COMPREHENSIVE STL vs MTL COMPARISON\")\n        print(\"=\"*80)\n        \n        for domain in self.results['STL']:\n            print(f\"\\nüè¢ {domain.upper()} DOMAIN:\")\n            print(\"-\" * 50)\n            \n            stl_results = self.results['STL'][domain]\n            mtl_results = self.results['MTL'].get(domain, {})\n            \n            stl_accs, stl_f1s = [], []\n            mtl_accs, mtl_f1s = [], []\n            \n            for aspect in stl_results:\n                stl_acc = stl_results[aspect]['accuracy']\n                stl_f1 = stl_results[aspect]['f1_score']\n                \n                stl_accs.append(stl_acc)\n                stl_f1s.append(stl_f1)\n                \n                if aspect in mtl_results:\n                    mtl_acc = mtl_results[aspect]['accuracy']\n                    mtl_f1 = mtl_results[aspect]['f1_score']\n                    \n                    mtl_accs.append(mtl_acc)\n                    mtl_f1s.append(mtl_f1)\n                    \n                    print(f\"  {aspect}:\")\n                    print(f\"    STL: Acc={stl_acc:.3f}, F1={stl_f1:.3f}\")\n                    print(f\"    MTL: Acc={mtl_acc:.3f}, F1={mtl_f1:.3f}\")\n                    print(f\"    Diff: Acc={mtl_acc-stl_acc:+.3f}, F1={mtl_f1-stl_f1:+.3f}\")\n            \n            if stl_accs and mtl_accs:\n                print(f\"\\n  üìà DOMAIN AVERAGE:\")\n                print(f\"    STL: Acc={np.mean(stl_accs):.3f}, F1={np.mean(stl_f1s):.3f}\")\n                print(f\"    MTL: Acc={np.mean(mtl_accs):.3f}, F1={np.mean(mtl_f1s):.3f}\")\n                print(f\"    MTL Improvement: Acc={np.mean(mtl_accs)-np.mean(stl_accs):+.3f}, F1={np.mean(mtl_f1s)-np.mean(stl_f1s):+.3f}\")\n        \n        # Key insights\n        print(f\"\\nüîç KEY INSIGHTS:\")\n        print(f\"  üéØ STL: M·ªói aspect c√≥ model ri√™ng bi·ªát\")\n        print(f\"  ü§ù MTL: M·ªôt model chia s·∫ª cho t·∫•t c·∫£ aspects\")\n        print(f\"  üí° MTL c√≥ th·ªÉ t·∫≠n d·ª•ng shared knowledge gi·ªØa aspects\")\n        print(f\"  ‚ö° STL c√≥ th·ªÉ t·∫≠p trung t·ªët h∆°n cho t·ª´ng aspect c·ª• th·ªÉ\")\n\ndef main():\n    print(\"üöÄ STL vs MTL COMPREHENSIVE COMPARISON\")\n    print(\"=\"*80)\n    \n    # Try GPU first, fallback to CPU if memory issues\n    try:\n        # Initialize comparison system with optimized settings\n        comparison = STL_vs_MTL_Comparison(\n            model_name=\"vinai/phobert-base\",\n            batch_size=1,  # Further reduced to 1\n            max_length=96  # Further reduced to 96\n        )\n        \n        # Load datasets\n        print(\"\\nüìö LOADING DATASETS...\")\n        \n        # Load datasets with error handling\n        domains_loaded = []\n        \n        try:\n            cosmetic_data = comparison.load_domain_data('cosmetic', '/kaggle/input/vrbp-data/full_data.csv')\n            domains_loaded.append('cosmetic')\n        except Exception as e:\n            print(f\"‚ùå Failed to load cosmetic data: {e}\")\n        \n        try:\n            hotel_data = comparison.load_domain_data('hotel', '/kaggle/input/vlsp-hotel')\n            domains_loaded.append('hotel')\n        except Exception as e:\n            print(f\"‚ùå Failed to load hotel data: {e}\")\n        \n        try:\n            restaurant_data = comparison.load_domain_data('restaurant', '/kaggle/input/vlsp-restaurant')\n            domains_loaded.append('restaurant')\n        except Exception as e:\n            print(f\"‚ùå Failed to load restaurant data: {e}\")\n        \n        # STL vs MTL Training for loaded domains only\n        for domain in domains_loaded:\n            if domain in comparison.datasets and len(comparison.datasets[domain]) > 0:\n                print(f\"\\n{'='*80}\")\n                print(f\"üîÑ TRAINING {domain.upper()} MODELS\")\n                print(f\"{'='*80}\")\n                \n                try:\n                    # Train STL models\n                    print(f\"üíæ GPU Memory before STL: {torch.cuda.memory_allocated()/1e9:.2f}GB\" if torch.cuda.is_available() else \"Using CPU\")\n                    comparison.train_stl_models(domain, epochs=1)\n                    \n                    # Train MTL model  \n                    print(f\"üíæ GPU Memory before MTL: {torch.cuda.memory_allocated()/1e9:.2f}GB\" if torch.cuda.is_available() else \"Using CPU\")\n                    comparison.train_mtl_model(domain, epochs=1)\n                    \n                except RuntimeError as e:\n                    if \"out of memory\" in str(e):\n                        print(f\"‚ùå GPU Memory exhausted for {domain}. Trying with CPU...\")\n                        comparison.clear_memory()\n                        \n                        # Create new comparison instance with CPU\n                        cpu_comparison = STL_vs_MTL_Comparison(\n                            model_name=\"vinai/phobert-base\",\n                            batch_size=2,  # Can use larger batch on CPU\n                            max_length=96,\n                            force_cpu=True\n                        )\n                        cpu_comparison.datasets[domain] = comparison.datasets[domain]\n                        \n                        try:\n                            cpu_comparison.train_stl_models(domain, epochs=1)\n                            cpu_comparison.train_mtl_model(domain, epochs=1)\n                            \n                            # Copy results back\n                            comparison.results['STL'][domain] = cpu_comparison.results['STL'][domain]\n                            comparison.results['MTL'][domain] = cpu_comparison.results['MTL'][domain]\n                            \n                            print(f\"‚úÖ {domain} completed using CPU\")\n                        except Exception as cpu_e:\n                            print(f\"‚ùå Failed to train {domain} even on CPU: {cpu_e}\")\n                    else:\n                        raise e\n            else:\n                print(f\"‚è≠Ô∏è  Skipping {domain} - no valid data loaded\")\n        \n        # Final comparison\n        comparison.comprehensive_comparison()\n        \n        print(\"\\n‚úÖ STL vs MTL Comparison Complete!\")\n        \n    except RuntimeError as e:\n        if \"out of memory\" in str(e):\n            print(\"\\n‚ùå GPU out of memory. Try these solutions:\")\n            print(\"   1. Use CPU mode: add force_cpu=True\")\n            print(\"   2. Reduce batch_size to 1\")\n            print(\"   3. Reduce max_length to 64 or 32\")\n            print(\"   4. Use smaller models:\")\n            print(\"      - 'distilbert-base-multilingual-cased' (smaller BERT)\")\n            print(\"      - 'xlm-roberta-base' (multilingual but smaller)\")\n            print(\"      - 'bert-base-multilingual-cased' (alternative)\")\n            print(\"\\n   Example with smaller model:\")\n            print(\"   comparison = STL_vs_MTL_Comparison(\")\n            print(\"       model_name='distilbert-base-multilingual-cased',\")\n            print(\"       batch_size=1, max_length=64, force_cpu=True)\")\n        else:\n            raise e\n    except Exception as e:\n        print(f\"\\n‚ùå Error occurred: {e}\")\n        print(\"Please check your data files and paths.\")\n\n# Alternative lightweight comparison for very limited memory\ndef lightweight_comparison():\n    \"\"\"Ultra-lightweight version for very limited memory\"\"\"\n    print(\"üöÄ LIGHTWEIGHT STL vs MTL COMPARISON\")\n    print(\"=\"*80)\n    \n    comparison = STL_vs_MTL_Comparison(\n        model_name=\"distilbert-base-multilingual-cased\",  # Smaller model\n        batch_size=1,\n        max_length=64,  # Very short sequences\n        force_cpu=True  # Force CPU usage\n    )\n    \n    # Load only cosmetic data for demo\n    try:\n        cosmetic_data = comparison.load_domain_data('cosmetic', '/kaggle/input/vrbp-data/full_data.csv')\n        if 'cosmetic' in comparison.datasets:\n            comparison.train_stl_models('cosmetic', epochs=1)\n            comparison.train_mtl_model('cosmetic', epochs=1)\n            comparison.comprehensive_comparison()\n    except Exception as e:\n        print(f\"‚ùå Error in lightweight comparison: {e}\")\n\nif __name__ == \"__main__\":\n    main() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:15:58.160238Z","iopub.execute_input":"2025-07-17T15:15:58.160919Z","iopub.status.idle":"2025-07-17T16:00:05.693690Z","shell.execute_reply.started":"2025-07-17T15:15:58.160893Z","shell.execute_reply":"2025-07-17T16:00:05.693039Z"}},"outputs":[{"name":"stdout","text":"üöÄ STL vs MTL COMPREHENSIVE COMPARISON\n================================================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/557 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e5f38af38404e3a9d5d0ec8ba440072"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf41579f6f11497f98b9c587d5c45dc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16a2ae37e6be4ea1aa9b475965dec7a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b1c30610edf463c909dc4299dd2d133"}},"metadata":{}},{"name":"stdout","text":"üöÄ STL vs MTL Comparison System\nüì± Device: cuda\nü§ñ Model: vinai/phobert-base\nüîß Batch size: 1, Max length: 96\nüíæ GPU Memory: 15.8GB total\nüíæ Available GPU Memory: 15.8GB\n\nüìö LOADING DATASETS...\n\nüìä Loading cosmetic domain...\n  ‚úÖ stayingpower: 2779 samples, 3 classes, min_class=318\n  ‚úÖ texture: 4887 samples, 3 classes, min_class=546\n  ‚úÖ smell: 2911 samples, 3 classes, min_class=130\n  ‚úÖ price: 3286 samples, 3 classes, min_class=21\n  ‚ùå others: Skipped (classes=1, min_class_count=2872)\n  ‚úÖ colour: 7519 samples, 3 classes, min_class=542\n  ‚úÖ shipping: 5469 samples, 3 classes, min_class=342\n  ‚úÖ packing: 3052 samples, 3 classes, min_class=18\n\nüìä Loading hotel domain...\n  ‚ùå FACILITIES#CLEANLINESS: Skipped (classes=3, min_class_count=1)\n  ‚ùå FACILITIES#COMFORT: Skipped (classes=3, min_class_count=1)\n  ‚úÖ FACILITIES#DESIGN&FEATURES: 745 samples, 3 classes, min_class=37\n  ‚úÖ FACILITIES#GENERAL: 281 samples, 3 classes, min_class=11\n\nüìä Loading restaurant domain...\n  ‚úÖ AMBIENCE#GENERAL: 942 samples, 3 classes, min_class=125\n  ‚úÖ DRINKS#PRICES: 146 samples, 3 classes, min_class=15\n  ‚úÖ DRINKS#QUALITY: 153 samples, 3 classes, min_class=15\n  ‚úÖ DRINKS#STYLE&OPTIONS: 112 samples, 3 classes, min_class=2\n  ‚úÖ FOOD#PRICES: 2125 samples, 3 classes, min_class=182\n\n================================================================================\nüîÑ TRAINING COSMETIC MODELS\n================================================================================\nüíæ GPU Memory before STL: 0.00GB\n\nüéØ TRAINING STL MODELS for COSMETIC\n============================================================\n\nüìà STL Training: stayingpower\n","output_type":"stream"},{"name":"stderr","text":"2025-07-17 15:16:17.931545: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752765378.137749      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752765378.193545      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/543M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4197748af9634d08a78cab955ad46b02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a3f710ee1a54931898dc3f06a32c489"}},"metadata":{}},{"name":"stderr","text":"\nSTL Epoch 1:   0%|          | 0/2223 [00:00<?, ?it/s]\u001b[A\nSTL Epoch 1:   0%|          | 1/2223 [00:00<21:35,  1.72it/s]\u001b[A\nSTL Epoch 1:   0%|          | 2/2223 [00:00<12:20,  3.00it/s]\u001b[A\nSTL Epoch 1:   0%|          | 4/2223 [00:00<06:09,  6.01it/s]\u001b[A\nSTL Epoch 1:   0%|          | 6/2223 [00:00<04:19,  8.56it/s]\u001b[A\nSTL Epoch 1:   0%|          | 8/2223 [00:01<03:41, 10.00it/s]\u001b[A\nSTL Epoch 1:   0%|          | 10/2223 [00:01<03:09, 11.65it/s]\u001b[A\nSTL Epoch 1:   1%|          | 12/2223 [00:01<02:48, 13.08it/s]\u001b[A\nSTL Epoch 1:   1%|          | 14/2223 [00:01<02:36, 14.14it/s]\u001b[A\nSTL Epoch 1:   1%|          | 16/2223 [00:01<02:38, 13.95it/s]\u001b[A\nSTL Epoch 1:   1%|          | 18/2223 [00:01<02:31, 14.59it/s]\u001b[A\nSTL Epoch 1:   1%|          | 20/2223 [00:01<02:25, 15.18it/s]\u001b[A\nSTL Epoch 1:   1%|          | 22/2223 [00:02<02:20, 15.67it/s]\u001b[A\nSTL Epoch 1:   1%|          | 24/2223 [00:02<02:26, 15.00it/s]\u001b[A\nSTL Epoch 1:   1%|          | 26/2223 [00:02<02:22, 15.38it/s]\u001b[A\nSTL Epoch 1:   1%|‚ñè         | 28/2223 [00:02<02:15, 16.23it/s]\u001b[A\nSTL Epoch 1:   1%|‚ñè         | 30/2223 [00:02<02:09, 16.89it/s]\u001b[A\nSTL Epoch 1:   1%|‚ñè         | 32/2223 [00:02<02:25, 15.07it/s]\u001b[A\nSTL Epoch 1:   2%|‚ñè         | 34/2223 [00:02<02:21, 15.49it/s]\u001b[A\nSTL Epoch 1:   2%|‚ñè         | 36/2223 [00:02<02:17, 15.92it/s]\u001b[A\nSTL Epoch 1:   2%|‚ñè         | 38/2223 [00:03<02:11, 16.59it/s]\u001b[A\nSTL Epoch 1:   2%|‚ñè         | 40/2223 [00:03<02:21, 15.48it/s]\u001b[A\nSTL Epoch 1:   2%|‚ñè         | 42/2223 [00:03<02:19, 15.67it/s]\u001b[A\nSTL Epoch 1:   2%|‚ñè         | 44/2223 [00:03<02:20, 15.50it/s]\u001b[A\nSTL Epoch 1:   2%|‚ñè         | 46/2223 [00:03<02:19, 15.56it/s]\u001b[A\nSTL Epoch 1:   2%|‚ñè         | 48/2223 [00:03<02:26, 14.82it/s]\u001b[A\nSTL Epoch 1:   2%|‚ñè         | 50/2223 [00:03<02:31, 14.30it/s]\u001b[A\nSTL Epoch 1:   2%|‚ñè         | 52/2223 [00:03<02:32, 14.28it/s]\u001b[A\nSTL Epoch 1:   2%|‚ñè         | 54/2223 [00:04<02:33, 14.14it/s]\u001b[A\nSTL Epoch 1:   3%|‚ñé         | 56/2223 [00:04<02:38, 13.66it/s]\u001b[A\nSTL Epoch 1:   3%|‚ñé         | 58/2223 [00:04<02:32, 14.23it/s]\u001b[A\nSTL Epoch 1:   3%|‚ñé         | 60/2223 [00:04<02:25, 14.82it/s]\u001b[A\nSTL Epoch 1:   3%|‚ñé         | 62/2223 [00:04<02:23, 15.09it/s]\u001b[A\nSTL Epoch 1:   3%|‚ñé         | 64/2223 [00:04<02:26, 14.71it/s]\u001b[A\nSTL Epoch 1:   3%|‚ñé         | 66/2223 [00:04<02:24, 14.92it/s]\u001b[A\nSTL Epoch 1:   3%|‚ñé         | 68/2223 [00:05<02:18, 15.52it/s]\u001b[A\nSTL Epoch 1:   3%|‚ñé         | 70/2223 [00:05<02:10, 16.46it/s]\u001b[A\nSTL Epoch 1:   3%|‚ñé         | 72/2223 [00:05<02:19, 15.41it/s]\u001b[A\nSTL Epoch 1:   3%|‚ñé         | 74/2223 [00:05<02:16, 15.77it/s]\u001b[A\nSTL Epoch 1:   3%|‚ñé         | 76/2223 [00:05<02:08, 16.67it/s]\u001b[A\nSTL Epoch 1:   4%|‚ñé         | 78/2223 [00:05<02:06, 16.94it/s]\u001b[A\nSTL Epoch 1:   4%|‚ñé         | 80/2223 [00:05<02:18, 15.51it/s]\u001b[A\nSTL Epoch 1:   4%|‚ñé         | 82/2223 [00:05<02:18, 15.44it/s]\u001b[A\nSTL Epoch 1:   4%|‚ñç         | 84/2223 [00:06<02:14, 15.86it/s]\u001b[A\nSTL Epoch 1:   4%|‚ñç         | 86/2223 [00:06<02:11, 16.22it/s]\u001b[A\nSTL Epoch 1:   4%|‚ñç         | 88/2223 [00:06<02:16, 15.62it/s]\u001b[A\nSTL Epoch 1:   4%|‚ñç         | 90/2223 [00:06<02:10, 16.31it/s]\u001b[A\nSTL Epoch 1:   4%|‚ñç         | 92/2223 [00:06<02:03, 17.21it/s]\u001b[A\nSTL Epoch 1:   4%|‚ñç         | 94/2223 [00:06<01:58, 17.90it/s]\u001b[A\nSTL Epoch 1:   4%|‚ñç         | 96/2223 [00:06<02:05, 16.94it/s]\u001b[A\nSTL Epoch 1:   4%|‚ñç         | 98/2223 [00:06<02:02, 17.31it/s]\u001b[A\nSTL Epoch 1:   4%|‚ñç         | 100/2223 [00:06<01:57, 18.02it/s]\u001b[A\nSTL Epoch 1:   5%|‚ñç         | 102/2223 [00:07<01:55, 18.36it/s]\u001b[A\nSTL Epoch 1:   5%|‚ñç         | 104/2223 [00:07<02:02, 17.27it/s]\u001b[A\nSTL Epoch 1:   5%|‚ñç         | 106/2223 [00:07<02:00, 17.56it/s]\u001b[A\nSTL Epoch 1:   5%|‚ñç         | 108/2223 [00:07<01:56, 18.19it/s]\u001b[A\nSTL Epoch 1:   5%|‚ñç         | 110/2223 [00:07<01:53, 18.67it/s]\u001b[A\nSTL Epoch 1:   5%|‚ñå         | 112/2223 [00:07<02:00, 17.50it/s]\u001b[A\nSTL Epoch 1:   5%|‚ñå         | 114/2223 [00:07<01:58, 17.81it/s]\u001b[A\nSTL Epoch 1:   5%|‚ñå         | 116/2223 [00:07<01:54, 18.41it/s]\u001b[A\nSTL Epoch 1:   5%|‚ñå         | 118/2223 [00:07<01:51, 18.82it/s]\u001b[A\nSTL Epoch 1:   5%|‚ñå         | 120/2223 [00:08<01:59, 17.55it/s]\u001b[A\nSTL Epoch 1:   5%|‚ñå         | 122/2223 [00:08<01:59, 17.61it/s]\u001b[A\nSTL Epoch 1:   6%|‚ñå         | 124/2223 [00:08<01:56, 17.96it/s]\u001b[A\nSTL Epoch 1:   6%|‚ñå         | 126/2223 [00:08<01:55, 18.18it/s]\u001b[A\nSTL Epoch 1:   6%|‚ñå         | 128/2223 [00:08<02:02, 17.09it/s]\u001b[A\nSTL Epoch 1:   6%|‚ñå         | 130/2223 [00:08<02:01, 17.16it/s]\u001b[A\nSTL Epoch 1:   6%|‚ñå         | 132/2223 [00:08<01:57, 17.81it/s]\u001b[A\nSTL Epoch 1:   6%|‚ñå         | 134/2223 [00:08<01:53, 18.36it/s]\u001b[A\nSTL Epoch 1:   6%|‚ñå         | 136/2223 [00:08<02:02, 17.04it/s]\u001b[A\nSTL Epoch 1:   6%|‚ñå         | 138/2223 [00:09<02:00, 17.36it/s]\u001b[A\nSTL Epoch 1:   6%|‚ñã         | 140/2223 [00:09<01:56, 17.95it/s]\u001b[A\nSTL Epoch 1:   6%|‚ñã         | 142/2223 [00:09<01:53, 18.40it/s]\u001b[A\nSTL Epoch 1:   6%|‚ñã         | 144/2223 [00:09<02:00, 17.28it/s]\u001b[A\nSTL Epoch 1:   7%|‚ñã         | 146/2223 [00:09<01:59, 17.44it/s]\u001b[A\nSTL Epoch 1:   7%|‚ñã         | 148/2223 [00:09<01:55, 17.97it/s]\u001b[A\nSTL Epoch 1:   7%|‚ñã         | 150/2223 [00:09<01:52, 18.45it/s]\u001b[A\nSTL Epoch 1:   7%|‚ñã         | 152/2223 [00:09<02:00, 17.20it/s]\u001b[A\nSTL Epoch 1:   7%|‚ñã         | 154/2223 [00:10<01:57, 17.56it/s]\u001b[A\nSTL Epoch 1:   7%|‚ñã         | 156/2223 [00:10<01:54, 18.12it/s]\u001b[A\nSTL Epoch 1:   7%|‚ñã         | 158/2223 [00:10<01:51, 18.58it/s]\u001b[A\nSTL Epoch 1:   7%|‚ñã         | 160/2223 [00:10<01:58, 17.40it/s]\u001b[A\nSTL Epoch 1:   7%|‚ñã         | 162/2223 [00:10<01:58, 17.47it/s]\u001b[A\nSTL Epoch 1:   7%|‚ñã         | 164/2223 [00:10<01:53, 18.12it/s]\u001b[A\nSTL Epoch 1:   7%|‚ñã         | 166/2223 [00:10<01:50, 18.63it/s]\u001b[A\nSTL Epoch 1:   8%|‚ñä         | 168/2223 [00:10<01:57, 17.47it/s]\u001b[A\nSTL Epoch 1:   8%|‚ñä         | 170/2223 [00:10<01:55, 17.73it/s]\u001b[A\nSTL Epoch 1:   8%|‚ñä         | 172/2223 [00:10<01:52, 18.30it/s]\u001b[A\nSTL Epoch 1:   8%|‚ñä         | 174/2223 [00:11<01:49, 18.75it/s]\u001b[A\nSTL Epoch 1:   8%|‚ñä         | 176/2223 [00:11<01:56, 17.52it/s]\u001b[A\nSTL Epoch 1:   8%|‚ñä         | 178/2223 [00:11<01:54, 17.81it/s]\u001b[A\nSTL Epoch 1:   8%|‚ñä         | 180/2223 [00:11<01:51, 18.35it/s]\u001b[A\nSTL Epoch 1:   8%|‚ñä         | 182/2223 [00:11<01:48, 18.74it/s]\u001b[A\nSTL Epoch 1:   8%|‚ñä         | 184/2223 [00:11<01:56, 17.52it/s]\u001b[A\nSTL Epoch 1:   8%|‚ñä         | 186/2223 [00:11<01:54, 17.80it/s]\u001b[A\nSTL Epoch 1:   8%|‚ñä         | 188/2223 [00:11<01:51, 18.24it/s]\u001b[A\nSTL Epoch 1:   9%|‚ñä         | 190/2223 [00:11<01:48, 18.65it/s]\u001b[A\nSTL Epoch 1:   9%|‚ñä         | 192/2223 [00:12<01:56, 17.44it/s]\u001b[A\nSTL Epoch 1:   9%|‚ñä         | 194/2223 [00:12<01:54, 17.76it/s]\u001b[A\nSTL Epoch 1:   9%|‚ñâ         | 196/2223 [00:12<01:50, 18.35it/s]\u001b[A\nSTL Epoch 1:   9%|‚ñâ         | 198/2223 [00:12<01:47, 18.81it/s]\u001b[A\nSTL Epoch 1:   9%|‚ñâ         | 200/2223 [00:12<01:55, 17.45it/s]\u001b[A\nSTL Epoch 1:   9%|‚ñâ         | 202/2223 [00:12<01:55, 17.52it/s]\u001b[A\nSTL Epoch 1:   9%|‚ñâ         | 204/2223 [00:12<01:53, 17.78it/s]\u001b[A\nSTL Epoch 1:   9%|‚ñâ         | 206/2223 [00:12<01:52, 17.88it/s]\u001b[A\nSTL Epoch 1:   9%|‚ñâ         | 208/2223 [00:13<01:59, 16.79it/s]\u001b[A\nSTL Epoch 1:   9%|‚ñâ         | 210/2223 [00:13<01:56, 17.25it/s]\u001b[A\nSTL Epoch 1:  10%|‚ñâ         | 212/2223 [00:13<01:52, 17.93it/s]\u001b[A\nSTL Epoch 1:  10%|‚ñâ         | 214/2223 [00:13<01:49, 18.42it/s]\u001b[A\nSTL Epoch 1:  10%|‚ñâ         | 216/2223 [00:13<01:55, 17.37it/s]\u001b[A\nSTL Epoch 1:  10%|‚ñâ         | 218/2223 [00:13<01:53, 17.68it/s]\u001b[A\nSTL Epoch 1:  10%|‚ñâ         | 220/2223 [00:13<01:49, 18.30it/s]\u001b[A\nSTL Epoch 1:  10%|‚ñâ         | 222/2223 [00:13<01:46, 18.74it/s]\u001b[A\nSTL Epoch 1:  10%|‚ñà         | 224/2223 [00:13<01:54, 17.50it/s]\u001b[A\nSTL Epoch 1:  10%|‚ñà         | 226/2223 [00:14<01:52, 17.77it/s]\u001b[A\nSTL Epoch 1:  10%|‚ñà         | 228/2223 [00:14<01:48, 18.34it/s]\u001b[A\nSTL Epoch 1:  10%|‚ñà         | 230/2223 [00:14<01:46, 18.78it/s]\u001b[A\nSTL Epoch 1:  10%|‚ñà         | 232/2223 [00:14<01:53, 17.55it/s]\u001b[A\nSTL Epoch 1:  11%|‚ñà         | 234/2223 [00:14<01:52, 17.72it/s]\u001b[A\nSTL Epoch 1:  11%|‚ñà         | 236/2223 [00:14<01:48, 18.29it/s]\u001b[A\nSTL Epoch 1:  11%|‚ñà         | 238/2223 [00:14<01:45, 18.75it/s]\u001b[A\nSTL Epoch 1:  11%|‚ñà         | 240/2223 [00:14<01:53, 17.51it/s]\u001b[A\nSTL Epoch 1:  11%|‚ñà         | 242/2223 [00:14<01:51, 17.72it/s]\u001b[A\nSTL Epoch 1:  11%|‚ñà         | 244/2223 [00:15<01:48, 18.27it/s]\u001b[A\nSTL Epoch 1:  11%|‚ñà         | 246/2223 [00:15<01:45, 18.73it/s]\u001b[A\nSTL Epoch 1:  11%|‚ñà         | 248/2223 [00:15<01:52, 17.52it/s]\u001b[A\nSTL Epoch 1:  11%|‚ñà         | 250/2223 [00:15<01:50, 17.83it/s]\u001b[A\nSTL Epoch 1:  11%|‚ñà‚ñè        | 252/2223 [00:15<01:47, 18.40it/s]\u001b[A\nSTL Epoch 1:  11%|‚ñà‚ñè        | 254/2223 [00:15<01:44, 18.80it/s]\u001b[A\nSTL Epoch 1:  12%|‚ñà‚ñè        | 256/2223 [00:15<01:52, 17.54it/s]\u001b[A\nSTL Epoch 1:  12%|‚ñà‚ñè        | 258/2223 [00:15<01:50, 17.86it/s]\u001b[A\nSTL Epoch 1:  12%|‚ñà‚ñè        | 260/2223 [00:15<01:46, 18.40it/s]\u001b[A\nSTL Epoch 1:  12%|‚ñà‚ñè        | 262/2223 [00:15<01:44, 18.79it/s]\u001b[A\nSTL Epoch 1:  12%|‚ñà‚ñè        | 264/2223 [00:16<01:51, 17.54it/s]\u001b[A\nSTL Epoch 1:  12%|‚ñà‚ñè        | 266/2223 [00:16<01:49, 17.82it/s]\u001b[A\nSTL Epoch 1:  12%|‚ñà‚ñè        | 268/2223 [00:16<01:46, 18.41it/s]\u001b[A\nSTL Epoch 1:  12%|‚ñà‚ñè        | 270/2223 [00:16<01:43, 18.80it/s]\u001b[A\nSTL Epoch 1:  12%|‚ñà‚ñè        | 272/2223 [00:16<01:51, 17.56it/s]\u001b[A\nSTL Epoch 1:  12%|‚ñà‚ñè        | 274/2223 [00:16<01:49, 17.84it/s]\u001b[A\nSTL Epoch 1:  12%|‚ñà‚ñè        | 276/2223 [00:16<01:45, 18.39it/s]\u001b[A\nSTL Epoch 1:  13%|‚ñà‚ñé        | 278/2223 [00:16<01:43, 18.81it/s]\u001b[A\nSTL Epoch 1:  13%|‚ñà‚ñé        | 280/2223 [00:16<01:50, 17.54it/s]\u001b[A\nSTL Epoch 1:  13%|‚ñà‚ñé        | 282/2223 [00:17<01:48, 17.86it/s]\u001b[A\nSTL Epoch 1:  13%|‚ñà‚ñé        | 284/2223 [00:17<01:45, 18.36it/s]\u001b[A\nSTL Epoch 1:  13%|‚ñà‚ñé        | 286/2223 [00:17<01:43, 18.76it/s]\u001b[A\nSTL Epoch 1:  13%|‚ñà‚ñé        | 288/2223 [00:17<01:50, 17.47it/s]\u001b[A\nSTL Epoch 1:  13%|‚ñà‚ñé        | 290/2223 [00:17<01:48, 17.76it/s]\u001b[A\nSTL Epoch 1:  13%|‚ñà‚ñé        | 292/2223 [00:17<01:45, 18.32it/s]\u001b[A\nSTL Epoch 1:  13%|‚ñà‚ñé        | 294/2223 [00:17<01:42, 18.77it/s]\u001b[A\nSTL Epoch 1:  13%|‚ñà‚ñé        | 296/2223 [00:17<01:49, 17.52it/s]\u001b[A\nSTL Epoch 1:  13%|‚ñà‚ñé        | 298/2223 [00:17<01:48, 17.73it/s]\u001b[A\nSTL Epoch 1:  13%|‚ñà‚ñé        | 300/2223 [00:18<01:45, 18.26it/s]\u001b[A\nSTL Epoch 1:  14%|‚ñà‚ñé        | 302/2223 [00:18<01:43, 18.64it/s]\u001b[A\nSTL Epoch 1:  14%|‚ñà‚ñé        | 304/2223 [00:18<01:50, 17.40it/s]\u001b[A\nSTL Epoch 1:  14%|‚ñà‚ñç        | 306/2223 [00:18<01:48, 17.68it/s]\u001b[A\nSTL Epoch 1:  14%|‚ñà‚ñç        | 308/2223 [00:18<01:44, 18.26it/s]\u001b[A\nSTL Epoch 1:  14%|‚ñà‚ñç        | 310/2223 [00:18<01:42, 18.69it/s]\u001b[A\nSTL Epoch 1:  14%|‚ñà‚ñç        | 312/2223 [00:18<01:49, 17.50it/s]\u001b[A\nSTL Epoch 1:  14%|‚ñà‚ñç        | 314/2223 [00:18<01:47, 17.77it/s]\u001b[A\nSTL Epoch 1:  14%|‚ñà‚ñç        | 316/2223 [00:18<01:44, 18.29it/s]\u001b[A\nSTL Epoch 1:  14%|‚ñà‚ñç        | 318/2223 [00:19<01:42, 18.66it/s]\u001b[A\nSTL Epoch 1:  14%|‚ñà‚ñç        | 320/2223 [00:19<01:49, 17.43it/s]\u001b[A\nSTL Epoch 1:  14%|‚ñà‚ñç        | 322/2223 [00:19<01:47, 17.75it/s]\u001b[A\nSTL Epoch 1:  15%|‚ñà‚ñç        | 324/2223 [00:19<01:43, 18.30it/s]\u001b[A\nSTL Epoch 1:  15%|‚ñà‚ñç        | 326/2223 [00:19<01:41, 18.73it/s]\u001b[A\nSTL Epoch 1:  15%|‚ñà‚ñç        | 328/2223 [00:19<01:48, 17.53it/s]\u001b[A\nSTL Epoch 1:  15%|‚ñà‚ñç        | 330/2223 [00:19<01:46, 17.82it/s]\u001b[A\nSTL Epoch 1:  15%|‚ñà‚ñç        | 332/2223 [00:19<01:42, 18.36it/s]\u001b[A\nSTL Epoch 1:  15%|‚ñà‚ñå        | 334/2223 [00:19<01:40, 18.76it/s]\u001b[A\nSTL Epoch 1:  15%|‚ñà‚ñå        | 336/2223 [00:20<01:47, 17.47it/s]\u001b[A\nSTL Epoch 1:  15%|‚ñà‚ñå        | 338/2223 [00:20<01:46, 17.76it/s]\u001b[A\nSTL Epoch 1:  15%|‚ñà‚ñå        | 340/2223 [00:20<01:42, 18.35it/s]\u001b[A\nSTL Epoch 1:  15%|‚ñà‚ñå        | 342/2223 [00:20<01:40, 18.78it/s]\u001b[A\nSTL Epoch 1:  15%|‚ñà‚ñå        | 344/2223 [00:20<01:47, 17.50it/s]\u001b[A\nSTL Epoch 1:  16%|‚ñà‚ñå        | 346/2223 [00:20<01:45, 17.79it/s]\u001b[A\nSTL Epoch 1:  16%|‚ñà‚ñå        | 348/2223 [00:20<01:42, 18.33it/s]\u001b[A\nSTL Epoch 1:  16%|‚ñà‚ñå        | 350/2223 [00:20<01:40, 18.69it/s]\u001b[A\nSTL Epoch 1:  16%|‚ñà‚ñå        | 352/2223 [00:20<01:47, 17.46it/s]\u001b[A\nSTL Epoch 1:  16%|‚ñà‚ñå        | 354/2223 [00:21<01:45, 17.77it/s]\u001b[A\nSTL Epoch 1:  16%|‚ñà‚ñå        | 356/2223 [00:21<01:42, 18.30it/s]\u001b[A\nSTL Epoch 1:  16%|‚ñà‚ñå        | 358/2223 [00:21<01:39, 18.73it/s]\u001b[A\nSTL Epoch 1:  16%|‚ñà‚ñå        | 360/2223 [00:21<01:46, 17.44it/s]\u001b[A\nSTL Epoch 1:  16%|‚ñà‚ñã        | 362/2223 [00:21<01:44, 17.80it/s]\u001b[A\nSTL Epoch 1:  16%|‚ñà‚ñã        | 365/2223 [00:21<01:33, 19.86it/s]\u001b[A\nSTL Epoch 1:  17%|‚ñà‚ñã        | 367/2223 [00:21<01:33, 19.81it/s]\u001b[A\nSTL Epoch 1:  17%|‚ñà‚ñã        | 369/2223 [00:21<01:43, 17.91it/s]\u001b[A\nSTL Epoch 1:  17%|‚ñà‚ñã        | 371/2223 [00:22<01:40, 18.40it/s]\u001b[A\nSTL Epoch 1:  17%|‚ñà‚ñã        | 373/2223 [00:22<01:38, 18.82it/s]\u001b[A\nSTL Epoch 1:  17%|‚ñà‚ñã        | 375/2223 [00:22<01:36, 19.11it/s]\u001b[A\nSTL Epoch 1:  17%|‚ñà‚ñã        | 377/2223 [00:22<01:45, 17.42it/s]\u001b[A\nSTL Epoch 1:  17%|‚ñà‚ñã        | 379/2223 [00:22<01:42, 18.06it/s]\u001b[A\nSTL Epoch 1:  17%|‚ñà‚ñã        | 381/2223 [00:22<01:41, 18.21it/s]\u001b[A\nSTL Epoch 1:  17%|‚ñà‚ñã        | 383/2223 [00:22<01:41, 18.13it/s]\u001b[A\nSTL Epoch 1:  17%|‚ñà‚ñã        | 385/2223 [00:22<01:50, 16.57it/s]\u001b[A\nSTL Epoch 1:  17%|‚ñà‚ñã        | 387/2223 [00:22<01:45, 17.45it/s]\u001b[A\nSTL Epoch 1:  17%|‚ñà‚ñã        | 389/2223 [00:23<01:41, 18.04it/s]\u001b[A\nSTL Epoch 1:  18%|‚ñà‚ñä        | 391/2223 [00:23<01:39, 18.49it/s]\u001b[A\nSTL Epoch 1:  18%|‚ñà‚ñä        | 393/2223 [00:23<01:47, 16.95it/s]\u001b[A\nSTL Epoch 1:  18%|‚ñà‚ñä        | 395/2223 [00:23<01:43, 17.73it/s]\u001b[A\nSTL Epoch 1:  18%|‚ñà‚ñä        | 397/2223 [00:23<01:39, 18.26it/s]\u001b[A\nSTL Epoch 1:  18%|‚ñà‚ñä        | 399/2223 [00:23<01:37, 18.70it/s]\u001b[A\nSTL Epoch 1:  18%|‚ñà‚ñä        | 401/2223 [00:23<01:46, 17.12it/s]\u001b[A\nSTL Epoch 1:  18%|‚ñà‚ñä        | 403/2223 [00:23<01:41, 17.87it/s]\u001b[A\nSTL Epoch 1:  18%|‚ñà‚ñä        | 405/2223 [00:23<01:38, 18.44it/s]\u001b[A\nSTL Epoch 1:  18%|‚ñà‚ñä        | 407/2223 [00:23<01:36, 18.85it/s]\u001b[A\nSTL Epoch 1:  18%|‚ñà‚ñä        | 409/2223 [00:24<01:45, 17.23it/s]\u001b[A\nSTL Epoch 1:  18%|‚ñà‚ñä        | 411/2223 [00:24<01:40, 17.94it/s]\u001b[A\nSTL Epoch 1:  19%|‚ñà‚ñä        | 413/2223 [00:24<01:38, 18.44it/s]\u001b[A\nSTL Epoch 1:  19%|‚ñà‚ñä        | 415/2223 [00:24<01:36, 18.80it/s]\u001b[A\nSTL Epoch 1:  19%|‚ñà‚ñâ        | 417/2223 [00:24<01:44, 17.21it/s]\u001b[A\nSTL Epoch 1:  19%|‚ñà‚ñâ        | 419/2223 [00:24<01:40, 17.94it/s]\u001b[A\nSTL Epoch 1:  19%|‚ñà‚ñâ        | 421/2223 [00:24<01:37, 18.41it/s]\u001b[A\nSTL Epoch 1:  19%|‚ñà‚ñâ        | 423/2223 [00:24<01:35, 18.83it/s]\u001b[A\nSTL Epoch 1:  19%|‚ñà‚ñâ        | 425/2223 [00:25<01:44, 17.22it/s]\u001b[A\nSTL Epoch 1:  19%|‚ñà‚ñâ        | 427/2223 [00:25<01:40, 17.91it/s]\u001b[A\nSTL Epoch 1:  19%|‚ñà‚ñâ        | 429/2223 [00:25<01:37, 18.45it/s]\u001b[A\nSTL Epoch 1:  19%|‚ñà‚ñâ        | 431/2223 [00:25<01:35, 18.83it/s]\u001b[A\nSTL Epoch 1:  19%|‚ñà‚ñâ        | 433/2223 [00:25<01:44, 17.21it/s]\u001b[A\nSTL Epoch 1:  20%|‚ñà‚ñâ        | 436/2223 [00:25<01:44, 17.18it/s]\u001b[A\nSTL Epoch 1:  20%|‚ñà‚ñâ        | 438/2223 [00:25<01:40, 17.80it/s]\u001b[A\nSTL Epoch 1:  20%|‚ñà‚ñâ        | 440/2223 [00:25<01:45, 16.93it/s]\u001b[A\nSTL Epoch 1:  20%|‚ñà‚ñâ        | 442/2223 [00:25<01:42, 17.35it/s]\u001b[A\nSTL Epoch 1:  20%|‚ñà‚ñâ        | 444/2223 [00:26<01:38, 17.99it/s]\u001b[A\nSTL Epoch 1:  20%|‚ñà‚ñà        | 446/2223 [00:26<01:36, 18.45it/s]\u001b[A\nSTL Epoch 1:  20%|‚ñà‚ñà        | 448/2223 [00:26<01:42, 17.32it/s]\u001b[A\nSTL Epoch 1:  20%|‚ñà‚ñà        | 450/2223 [00:26<01:40, 17.65it/s]\u001b[A\nSTL Epoch 1:  20%|‚ñà‚ñà        | 452/2223 [00:26<01:37, 18.21it/s]\u001b[A\nSTL Epoch 1:  20%|‚ñà‚ñà        | 454/2223 [00:26<01:34, 18.63it/s]\u001b[A\nSTL Epoch 1:  21%|‚ñà‚ñà        | 456/2223 [00:26<01:41, 17.41it/s]\u001b[A\nSTL Epoch 1:  21%|‚ñà‚ñà        | 458/2223 [00:26<01:39, 17.70it/s]\u001b[A\nSTL Epoch 1:  21%|‚ñà‚ñà        | 460/2223 [00:26<01:36, 18.23it/s]\u001b[A\nSTL Epoch 1:  21%|‚ñà‚ñà        | 462/2223 [00:27<01:34, 18.68it/s]\u001b[A\nSTL Epoch 1:  21%|‚ñà‚ñà        | 464/2223 [00:27<01:40, 17.47it/s]\u001b[A\nSTL Epoch 1:  21%|‚ñà‚ñà        | 466/2223 [00:27<01:38, 17.76it/s]\u001b[A\nSTL Epoch 1:  21%|‚ñà‚ñà        | 468/2223 [00:27<01:35, 18.30it/s]\u001b[A\nSTL Epoch 1:  21%|‚ñà‚ñà        | 470/2223 [00:27<01:33, 18.74it/s]\u001b[A\nSTL Epoch 1:  21%|‚ñà‚ñà        | 472/2223 [00:27<01:40, 17.50it/s]\u001b[A\nSTL Epoch 1:  21%|‚ñà‚ñà‚ñè       | 474/2223 [00:27<01:38, 17.80it/s]\u001b[A\nSTL Epoch 1:  21%|‚ñà‚ñà‚ñè       | 476/2223 [00:27<01:35, 18.39it/s]\u001b[A\nSTL Epoch 1:  22%|‚ñà‚ñà‚ñè       | 478/2223 [00:27<01:32, 18.77it/s]\u001b[A\nSTL Epoch 1:  22%|‚ñà‚ñà‚ñè       | 480/2223 [00:28<01:39, 17.51it/s]\u001b[A\nSTL Epoch 1:  22%|‚ñà‚ñà‚ñè       | 482/2223 [00:28<01:38, 17.76it/s]\u001b[A\nSTL Epoch 1:  22%|‚ñà‚ñà‚ñè       | 484/2223 [00:28<01:35, 18.27it/s]\u001b[A\nSTL Epoch 1:  22%|‚ñà‚ñà‚ñè       | 486/2223 [00:28<01:33, 18.61it/s]\u001b[A\nSTL Epoch 1:  22%|‚ñà‚ñà‚ñè       | 488/2223 [00:28<01:40, 17.30it/s]\u001b[A\nSTL Epoch 1:  22%|‚ñà‚ñà‚ñè       | 490/2223 [00:28<01:38, 17.57it/s]\u001b[A\nSTL Epoch 1:  22%|‚ñà‚ñà‚ñè       | 492/2223 [00:28<01:40, 17.31it/s]\u001b[A\nSTL Epoch 1:  22%|‚ñà‚ñà‚ñè       | 494/2223 [00:28<01:36, 17.87it/s]\u001b[A\nSTL Epoch 1:  22%|‚ñà‚ñà‚ñè       | 496/2223 [00:29<01:43, 16.64it/s]\u001b[A\nSTL Epoch 1:  22%|‚ñà‚ñà‚ñè       | 498/2223 [00:29<01:42, 16.87it/s]\u001b[A\nSTL Epoch 1:  22%|‚ñà‚ñà‚ñè       | 500/2223 [00:29<01:38, 17.55it/s]\u001b[A\nSTL Epoch 1:  23%|‚ñà‚ñà‚ñé       | 502/2223 [00:29<01:34, 18.12it/s]\u001b[A\nSTL Epoch 1:  23%|‚ñà‚ñà‚ñé       | 504/2223 [00:29<01:40, 17.05it/s]\u001b[A\nSTL Epoch 1:  23%|‚ñà‚ñà‚ñé       | 506/2223 [00:29<01:38, 17.40it/s]\u001b[A\nSTL Epoch 1:  23%|‚ñà‚ñà‚ñé       | 508/2223 [00:29<01:38, 17.42it/s]\u001b[A\nSTL Epoch 1:  23%|‚ñà‚ñà‚ñé       | 510/2223 [00:29<01:37, 17.56it/s]\u001b[A\nSTL Epoch 1:  23%|‚ñà‚ñà‚ñé       | 512/2223 [00:29<01:44, 16.36it/s]\u001b[A\nSTL Epoch 1:  23%|‚ñà‚ñà‚ñé       | 514/2223 [00:30<01:41, 16.81it/s]\u001b[A\nSTL Epoch 1:  23%|‚ñà‚ñà‚ñé       | 516/2223 [00:30<01:37, 17.54it/s]\u001b[A\nSTL Epoch 1:  23%|‚ñà‚ñà‚ñé       | 518/2223 [00:30<01:34, 18.05it/s]\u001b[A\nSTL Epoch 1:  23%|‚ñà‚ñà‚ñé       | 520/2223 [00:30<01:40, 16.99it/s]\u001b[A\nSTL Epoch 1:  23%|‚ñà‚ñà‚ñé       | 522/2223 [00:30<01:37, 17.42it/s]\u001b[A\nSTL Epoch 1:  24%|‚ñà‚ñà‚ñé       | 524/2223 [00:30<01:34, 18.05it/s]\u001b[A\nSTL Epoch 1:  24%|‚ñà‚ñà‚ñé       | 526/2223 [00:30<01:31, 18.56it/s]\u001b[A\nSTL Epoch 1:  24%|‚ñà‚ñà‚ñç       | 528/2223 [00:30<01:37, 17.34it/s]\u001b[A\nSTL Epoch 1:  24%|‚ñà‚ñà‚ñç       | 530/2223 [00:30<01:36, 17.55it/s]\u001b[A\nSTL Epoch 1:  24%|‚ñà‚ñà‚ñç       | 532/2223 [00:31<01:33, 18.16it/s]\u001b[A\nSTL Epoch 1:  24%|‚ñà‚ñà‚ñç       | 534/2223 [00:31<01:30, 18.60it/s]\u001b[A\nSTL Epoch 1:  24%|‚ñà‚ñà‚ñç       | 536/2223 [00:31<01:37, 17.34it/s]\u001b[A\nSTL Epoch 1:  24%|‚ñà‚ñà‚ñç       | 538/2223 [00:31<01:35, 17.64it/s]\u001b[A\nSTL Epoch 1:  24%|‚ñà‚ñà‚ñç       | 540/2223 [00:31<01:32, 18.18it/s]\u001b[A\nSTL Epoch 1:  24%|‚ñà‚ñà‚ñç       | 542/2223 [00:31<01:30, 18.61it/s]\u001b[A\nSTL Epoch 1:  24%|‚ñà‚ñà‚ñç       | 544/2223 [00:31<01:36, 17.34it/s]\u001b[A\nSTL Epoch 1:  25%|‚ñà‚ñà‚ñç       | 546/2223 [00:31<01:34, 17.68it/s]\u001b[A\nSTL Epoch 1:  25%|‚ñà‚ñà‚ñç       | 548/2223 [00:31<01:32, 18.13it/s]\u001b[A\nSTL Epoch 1:  25%|‚ñà‚ñà‚ñç       | 550/2223 [00:32<01:29, 18.62it/s]\u001b[A\nSTL Epoch 1:  25%|‚ñà‚ñà‚ñç       | 552/2223 [00:32<01:36, 17.38it/s]\u001b[A\nSTL Epoch 1:  25%|‚ñà‚ñà‚ñç       | 554/2223 [00:32<01:34, 17.68it/s]\u001b[A\nSTL Epoch 1:  25%|‚ñà‚ñà‚ñå       | 556/2223 [00:32<01:31, 18.23it/s]\u001b[A\nSTL Epoch 1:  25%|‚ñà‚ñà‚ñå       | 558/2223 [00:32<01:29, 18.68it/s]\u001b[A\nSTL Epoch 1:  25%|‚ñà‚ñà‚ñå       | 560/2223 [00:32<01:35, 17.36it/s]\u001b[A\nSTL Epoch 1:  25%|‚ñà‚ñà‚ñå       | 562/2223 [00:32<01:37, 17.05it/s]\u001b[A\nSTL Epoch 1:  25%|‚ñà‚ñà‚ñå       | 564/2223 [00:32<01:33, 17.77it/s]\u001b[A\nSTL Epoch 1:  25%|‚ñà‚ñà‚ñå       | 566/2223 [00:32<01:30, 18.25it/s]\u001b[A\nSTL Epoch 1:  26%|‚ñà‚ñà‚ñå       | 568/2223 [00:33<01:36, 17.18it/s]\u001b[A\nSTL Epoch 1:  26%|‚ñà‚ñà‚ñå       | 570/2223 [00:33<01:34, 17.55it/s]\u001b[A\nSTL Epoch 1:  26%|‚ñà‚ñà‚ñå       | 572/2223 [00:33<01:31, 18.04it/s]\u001b[A\nSTL Epoch 1:  26%|‚ñà‚ñà‚ñå       | 574/2223 [00:33<01:30, 18.31it/s]\u001b[A\nSTL Epoch 1:  26%|‚ñà‚ñà‚ñå       | 576/2223 [00:33<01:36, 17.01it/s]\u001b[A\nSTL Epoch 1:  26%|‚ñà‚ñà‚ñå       | 578/2223 [00:33<01:35, 17.23it/s]\u001b[A\nSTL Epoch 1:  26%|‚ñà‚ñà‚ñå       | 580/2223 [00:33<01:31, 17.88it/s]\u001b[A\nSTL Epoch 1:  26%|‚ñà‚ñà‚ñå       | 582/2223 [00:33<01:29, 18.38it/s]\u001b[A\nSTL Epoch 1:  26%|‚ñà‚ñà‚ñã       | 584/2223 [00:33<01:35, 17.19it/s]\u001b[A\nSTL Epoch 1:  26%|‚ñà‚ñà‚ñã       | 586/2223 [00:34<01:33, 17.46it/s]\u001b[A\nSTL Epoch 1:  26%|‚ñà‚ñà‚ñã       | 588/2223 [00:34<01:30, 18.05it/s]\u001b[A\nSTL Epoch 1:  27%|‚ñà‚ñà‚ñã       | 590/2223 [00:34<01:28, 18.53it/s]\u001b[A\nSTL Epoch 1:  27%|‚ñà‚ñà‚ñã       | 592/2223 [00:34<01:34, 17.28it/s]\u001b[A\nSTL Epoch 1:  27%|‚ñà‚ñà‚ñã       | 594/2223 [00:34<01:32, 17.61it/s]\u001b[A\nSTL Epoch 1:  27%|‚ñà‚ñà‚ñã       | 596/2223 [00:34<01:29, 18.17it/s]\u001b[A\nSTL Epoch 1:  27%|‚ñà‚ñà‚ñã       | 598/2223 [00:34<01:27, 18.62it/s]\u001b[A\nSTL Epoch 1:  27%|‚ñà‚ñà‚ñã       | 600/2223 [00:34<01:34, 17.25it/s]\u001b[A\nSTL Epoch 1:  27%|‚ñà‚ñà‚ñã       | 602/2223 [00:35<01:39, 16.24it/s]\u001b[A\nSTL Epoch 1:  27%|‚ñà‚ñà‚ñã       | 604/2223 [00:35<01:38, 16.39it/s]\u001b[A\nSTL Epoch 1:  27%|‚ñà‚ñà‚ñã       | 606/2223 [00:35<01:37, 16.56it/s]\u001b[A\nSTL Epoch 1:  27%|‚ñà‚ñà‚ñã       | 608/2223 [00:35<01:45, 15.28it/s]\u001b[A\nSTL Epoch 1:  27%|‚ñà‚ñà‚ñã       | 610/2223 [00:35<01:40, 15.99it/s]\u001b[A\nSTL Epoch 1:  28%|‚ñà‚ñà‚ñä       | 612/2223 [00:35<01:35, 16.92it/s]\u001b[A\nSTL Epoch 1:  28%|‚ñà‚ñà‚ñä       | 614/2223 [00:35<01:30, 17.70it/s]\u001b[A\nSTL Epoch 1:  28%|‚ñà‚ñà‚ñä       | 616/2223 [00:35<01:35, 16.81it/s]\u001b[A\nSTL Epoch 1:  28%|‚ñà‚ñà‚ñä       | 618/2223 [00:35<01:33, 17.18it/s]\u001b[A\nSTL Epoch 1:  28%|‚ñà‚ñà‚ñä       | 620/2223 [00:36<01:29, 17.88it/s]\u001b[A\nSTL Epoch 1:  28%|‚ñà‚ñà‚ñä       | 622/2223 [00:36<01:27, 18.34it/s]\u001b[A\nSTL Epoch 1:  28%|‚ñà‚ñà‚ñä       | 624/2223 [00:36<01:32, 17.22it/s]\u001b[A\nSTL Epoch 1:  28%|‚ñà‚ñà‚ñä       | 626/2223 [00:36<01:31, 17.53it/s]\u001b[A\nSTL Epoch 1:  28%|‚ñà‚ñà‚ñä       | 628/2223 [00:36<01:28, 18.08it/s]\u001b[A\nSTL Epoch 1:  28%|‚ñà‚ñà‚ñä       | 630/2223 [00:36<01:25, 18.52it/s]\u001b[A\nSTL Epoch 1:  28%|‚ñà‚ñà‚ñä       | 632/2223 [00:36<01:32, 17.27it/s]\u001b[A\nSTL Epoch 1:  29%|‚ñà‚ñà‚ñä       | 634/2223 [00:36<01:30, 17.57it/s]\u001b[A\nSTL Epoch 1:  29%|‚ñà‚ñà‚ñä       | 636/2223 [00:36<01:28, 18.01it/s]\u001b[A\nSTL Epoch 1:  29%|‚ñà‚ñà‚ñä       | 638/2223 [00:37<01:25, 18.50it/s]\u001b[A\nSTL Epoch 1:  29%|‚ñà‚ñà‚ñâ       | 640/2223 [00:37<01:31, 17.29it/s]\u001b[A\nSTL Epoch 1:  29%|‚ñà‚ñà‚ñâ       | 642/2223 [00:37<01:29, 17.60it/s]\u001b[A\nSTL Epoch 1:  29%|‚ñà‚ñà‚ñâ       | 644/2223 [00:37<01:26, 18.17it/s]\u001b[A\nSTL Epoch 1:  29%|‚ñà‚ñà‚ñâ       | 646/2223 [00:37<01:24, 18.61it/s]\u001b[A\nSTL Epoch 1:  29%|‚ñà‚ñà‚ñâ       | 648/2223 [00:37<01:30, 17.34it/s]\u001b[A\nSTL Epoch 1:  29%|‚ñà‚ñà‚ñâ       | 650/2223 [00:37<01:29, 17.61it/s]\u001b[A\nSTL Epoch 1:  29%|‚ñà‚ñà‚ñâ       | 652/2223 [00:37<01:26, 18.18it/s]\u001b[A\nSTL Epoch 1:  29%|‚ñà‚ñà‚ñâ       | 654/2223 [00:37<01:24, 18.50it/s]\u001b[A\nSTL Epoch 1:  30%|‚ñà‚ñà‚ñâ       | 656/2223 [00:38<01:30, 17.24it/s]\u001b[A\nSTL Epoch 1:  30%|‚ñà‚ñà‚ñâ       | 658/2223 [00:38<01:29, 17.56it/s]\u001b[A\nSTL Epoch 1:  30%|‚ñà‚ñà‚ñâ       | 660/2223 [00:38<01:26, 18.14it/s]\u001b[A\nSTL Epoch 1:  30%|‚ñà‚ñà‚ñâ       | 662/2223 [00:38<01:23, 18.63it/s]\u001b[A\nSTL Epoch 1:  30%|‚ñà‚ñà‚ñâ       | 664/2223 [00:38<01:29, 17.38it/s]\u001b[A\nSTL Epoch 1:  30%|‚ñà‚ñà‚ñâ       | 666/2223 [00:38<01:28, 17.61it/s]\u001b[A\nSTL Epoch 1:  30%|‚ñà‚ñà‚ñà       | 668/2223 [00:38<01:26, 18.00it/s]\u001b[A\nSTL Epoch 1:  30%|‚ñà‚ñà‚ñà       | 670/2223 [00:38<01:24, 18.45it/s]\u001b[A\nSTL Epoch 1:  30%|‚ñà‚ñà‚ñà       | 672/2223 [00:38<01:30, 17.10it/s]\u001b[A\nSTL Epoch 1:  30%|‚ñà‚ñà‚ñà       | 674/2223 [00:39<01:29, 17.40it/s]\u001b[A\nSTL Epoch 1:  30%|‚ñà‚ñà‚ñà       | 676/2223 [00:39<01:26, 17.92it/s]\u001b[A\nSTL Epoch 1:  30%|‚ñà‚ñà‚ñà       | 678/2223 [00:39<01:24, 18.34it/s]\u001b[A\nSTL Epoch 1:  31%|‚ñà‚ñà‚ñà       | 680/2223 [00:39<01:30, 17.13it/s]\u001b[A\nSTL Epoch 1:  31%|‚ñà‚ñà‚ñà       | 682/2223 [00:39<01:28, 17.43it/s]\u001b[A\nSTL Epoch 1:  31%|‚ñà‚ñà‚ñà       | 684/2223 [00:39<01:25, 17.98it/s]\u001b[A\nSTL Epoch 1:  31%|‚ñà‚ñà‚ñà       | 686/2223 [00:39<01:23, 18.41it/s]\u001b[A\nSTL Epoch 1:  31%|‚ñà‚ñà‚ñà       | 688/2223 [00:39<01:29, 17.12it/s]\u001b[A\nSTL Epoch 1:  31%|‚ñà‚ñà‚ñà       | 690/2223 [00:40<01:28, 17.35it/s]\u001b[A\nSTL Epoch 1:  31%|‚ñà‚ñà‚ñà       | 692/2223 [00:40<01:25, 17.91it/s]\u001b[A\nSTL Epoch 1:  31%|‚ñà‚ñà‚ñà       | 694/2223 [00:40<01:23, 18.32it/s]\u001b[A\nSTL Epoch 1:  31%|‚ñà‚ñà‚ñà‚ñè      | 696/2223 [00:40<01:29, 17.09it/s]\u001b[A\nSTL Epoch 1:  31%|‚ñà‚ñà‚ñà‚ñè      | 698/2223 [00:40<01:27, 17.44it/s]\u001b[A\nSTL Epoch 1:  31%|‚ñà‚ñà‚ñà‚ñè      | 700/2223 [00:40<01:24, 18.00it/s]\u001b[A\nSTL Epoch 1:  32%|‚ñà‚ñà‚ñà‚ñè      | 702/2223 [00:40<01:22, 18.45it/s]\u001b[A\nSTL Epoch 1:  32%|‚ñà‚ñà‚ñà‚ñè      | 704/2223 [00:40<01:28, 17.24it/s]\u001b[A\nSTL Epoch 1:  32%|‚ñà‚ñà‚ñà‚ñè      | 706/2223 [00:40<01:26, 17.61it/s]\u001b[A\nSTL Epoch 1:  32%|‚ñà‚ñà‚ñà‚ñè      | 708/2223 [00:41<01:23, 18.16it/s]\u001b[A\nSTL Epoch 1:  32%|‚ñà‚ñà‚ñà‚ñè      | 710/2223 [00:41<01:21, 18.61it/s]\u001b[A\nSTL Epoch 1:  32%|‚ñà‚ñà‚ñà‚ñè      | 712/2223 [00:41<01:27, 17.28it/s]\u001b[A\nSTL Epoch 1:  32%|‚ñà‚ñà‚ñà‚ñè      | 714/2223 [00:41<01:25, 17.62it/s]\u001b[A\nSTL Epoch 1:  32%|‚ñà‚ñà‚ñà‚ñè      | 716/2223 [00:41<01:22, 18.19it/s]\u001b[A\nSTL Epoch 1:  32%|‚ñà‚ñà‚ñà‚ñè      | 718/2223 [00:41<01:20, 18.60it/s]\u001b[A\nSTL Epoch 1:  32%|‚ñà‚ñà‚ñà‚ñè      | 720/2223 [00:41<01:26, 17.34it/s]\u001b[A\nSTL Epoch 1:  32%|‚ñà‚ñà‚ñà‚ñè      | 722/2223 [00:41<01:24, 17.70it/s]\u001b[A\nSTL Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 724/2223 [00:41<01:22, 18.24it/s]\u001b[A\nSTL Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 726/2223 [00:42<01:20, 18.67it/s]\u001b[A\nSTL Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 728/2223 [00:42<01:26, 17.34it/s]\u001b[A\nSTL Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 730/2223 [00:42<01:24, 17.66it/s]\u001b[A\nSTL Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 732/2223 [00:42<01:21, 18.23it/s]\u001b[A\nSTL Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 734/2223 [00:42<01:19, 18.65it/s]\u001b[A\nSTL Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 736/2223 [00:42<01:28, 16.78it/s]\u001b[A\nSTL Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 738/2223 [00:42<01:31, 16.25it/s]\u001b[A\nSTL Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 740/2223 [00:42<01:26, 17.13it/s]\u001b[A\nSTL Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 742/2223 [00:42<01:23, 17.79it/s]\u001b[A\nSTL Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 744/2223 [00:43<01:27, 16.81it/s]\u001b[A\nSTL Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñé      | 746/2223 [00:43<01:25, 17.26it/s]\u001b[A\nSTL Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñé      | 748/2223 [00:43<01:22, 17.88it/s]\u001b[A\nSTL Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñé      | 750/2223 [00:43<01:20, 18.38it/s]\u001b[A\nSTL Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñç      | 752/2223 [00:43<01:25, 17.19it/s]\u001b[A\nSTL Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñç      | 754/2223 [00:43<01:23, 17.54it/s]\u001b[A\nSTL Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñç      | 756/2223 [00:43<01:21, 18.05it/s]\u001b[A\nSTL Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñç      | 758/2223 [00:43<01:18, 18.55it/s]\u001b[A\nSTL Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñç      | 760/2223 [00:43<01:24, 17.25it/s]\u001b[A\nSTL Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñç      | 762/2223 [00:44<01:23, 17.57it/s]\u001b[A\nSTL Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñç      | 764/2223 [00:44<01:20, 18.07it/s]\u001b[A\nSTL Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñç      | 766/2223 [00:44<01:18, 18.55it/s]\u001b[A\nSTL Epoch 1:  35%|‚ñà‚ñà‚ñà‚ñç      | 768/2223 [00:44<01:24, 17.30it/s]\u001b[A\nSTL Epoch 1:  35%|‚ñà‚ñà‚ñà‚ñç      | 770/2223 [00:44<01:22, 17.65it/s]\u001b[A\nSTL Epoch 1:  35%|‚ñà‚ñà‚ñà‚ñç      | 772/2223 [00:44<01:19, 18.19it/s]\u001b[A\nSTL Epoch 1:  35%|‚ñà‚ñà‚ñà‚ñç      | 774/2223 [00:44<01:17, 18.65it/s]\u001b[A\nSTL Epoch 1:  35%|‚ñà‚ñà‚ñà‚ñç      | 776/2223 [00:44<01:23, 17.31it/s]\u001b[A\nSTL Epoch 1:  35%|‚ñà‚ñà‚ñà‚ñç      | 778/2223 [00:44<01:22, 17.57it/s]\u001b[A\nSTL Epoch 1:  35%|‚ñà‚ñà‚ñà‚ñå      | 780/2223 [00:45<01:19, 18.17it/s]\u001b[A\nSTL Epoch 1:  35%|‚ñà‚ñà‚ñà‚ñå      | 782/2223 [00:45<01:17, 18.59it/s]\u001b[A\nSTL Epoch 1:  35%|‚ñà‚ñà‚ñà‚ñå      | 784/2223 [00:45<01:23, 17.32it/s]\u001b[A\nSTL Epoch 1:  35%|‚ñà‚ñà‚ñà‚ñå      | 786/2223 [00:45<01:21, 17.65it/s]\u001b[A\nSTL Epoch 1:  35%|‚ñà‚ñà‚ñà‚ñå      | 788/2223 [00:45<01:18, 18.25it/s]\u001b[A\nSTL Epoch 1:  36%|‚ñà‚ñà‚ñà‚ñå      | 790/2223 [00:45<01:16, 18.70it/s]\u001b[A\nSTL Epoch 1:  36%|‚ñà‚ñà‚ñà‚ñå      | 792/2223 [00:45<01:22, 17.37it/s]\u001b[A\nSTL Epoch 1:  36%|‚ñà‚ñà‚ñà‚ñå      | 794/2223 [00:45<01:20, 17.70it/s]\u001b[A\nSTL Epoch 1:  36%|‚ñà‚ñà‚ñà‚ñå      | 796/2223 [00:45<01:18, 18.21it/s]\u001b[A\nSTL Epoch 1:  36%|‚ñà‚ñà‚ñà‚ñå      | 798/2223 [00:46<01:16, 18.63it/s]\u001b[A\nSTL Epoch 1:  36%|‚ñà‚ñà‚ñà‚ñå      | 800/2223 [00:46<01:22, 17.29it/s]\u001b[A\nSTL Epoch 1:  36%|‚ñà‚ñà‚ñà‚ñå      | 802/2223 [00:46<01:20, 17.66it/s]\u001b[A\nSTL Epoch 1:  36%|‚ñà‚ñà‚ñà‚ñå      | 804/2223 [00:46<01:17, 18.24it/s]\u001b[A\nSTL Epoch 1:  36%|‚ñà‚ñà‚ñà‚ñã      | 806/2223 [00:46<01:15, 18.69it/s]\u001b[A\nSTL Epoch 1:  36%|‚ñà‚ñà‚ñà‚ñã      | 808/2223 [00:46<01:21, 17.35it/s]\u001b[A\nSTL Epoch 1:  36%|‚ñà‚ñà‚ñà‚ñã      | 810/2223 [00:46<01:19, 17.67it/s]\u001b[A\nSTL Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 812/2223 [00:46<01:17, 18.21it/s]\u001b[A\nSTL Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 814/2223 [00:46<01:15, 18.62it/s]\u001b[A\nSTL Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 816/2223 [00:47<01:21, 17.32it/s]\u001b[A\nSTL Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 818/2223 [00:47<01:19, 17.60it/s]\u001b[A\nSTL Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 820/2223 [00:47<01:17, 18.19it/s]\u001b[A\nSTL Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 822/2223 [00:47<01:15, 18.66it/s]\u001b[A\nSTL Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 824/2223 [00:47<01:20, 17.35it/s]\u001b[A\nSTL Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 826/2223 [00:47<01:18, 17.73it/s]\u001b[A\nSTL Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 828/2223 [00:47<01:16, 18.23it/s]\u001b[A\nSTL Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 830/2223 [00:47<01:14, 18.68it/s]\u001b[A\nSTL Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 832/2223 [00:47<01:20, 17.38it/s]\u001b[A\nSTL Epoch 1:  38%|‚ñà‚ñà‚ñà‚ñä      | 834/2223 [00:48<01:18, 17.68it/s]\u001b[A\nSTL Epoch 1:  38%|‚ñà‚ñà‚ñà‚ñä      | 836/2223 [00:48<01:16, 18.16it/s]\u001b[A\nSTL Epoch 1:  38%|‚ñà‚ñà‚ñà‚ñä      | 838/2223 [00:48<01:14, 18.61it/s]\u001b[A\nSTL Epoch 1:  38%|‚ñà‚ñà‚ñà‚ñä      | 840/2223 [00:48<01:19, 17.31it/s]\u001b[A\nSTL Epoch 1:  38%|‚ñà‚ñà‚ñà‚ñä      | 842/2223 [00:48<01:18, 17.64it/s]\u001b[A\nSTL Epoch 1:  38%|‚ñà‚ñà‚ñà‚ñä      | 844/2223 [00:48<01:15, 18.20it/s]\u001b[A\nSTL Epoch 1:  38%|‚ñà‚ñà‚ñà‚ñä      | 846/2223 [00:48<01:13, 18.61it/s]\u001b[A\nSTL Epoch 1:  38%|‚ñà‚ñà‚ñà‚ñä      | 848/2223 [00:48<01:19, 17.30it/s]\u001b[A\nSTL Epoch 1:  38%|‚ñà‚ñà‚ñà‚ñä      | 850/2223 [00:48<01:18, 17.52it/s]\u001b[A\nSTL Epoch 1:  38%|‚ñà‚ñà‚ñà‚ñä      | 852/2223 [00:49<01:15, 18.13it/s]\u001b[A\nSTL Epoch 1:  38%|‚ñà‚ñà‚ñà‚ñä      | 854/2223 [00:49<01:14, 18.48it/s]\u001b[A\nSTL Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñä      | 856/2223 [00:49<01:19, 17.17it/s]\u001b[A\nSTL Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñä      | 858/2223 [00:49<01:17, 17.55it/s]\u001b[A\nSTL Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñä      | 860/2223 [00:49<01:15, 18.17it/s]\u001b[A\nSTL Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 862/2223 [00:49<01:13, 18.61it/s]\u001b[A\nSTL Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 864/2223 [00:49<01:18, 17.30it/s]\u001b[A\nSTL Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 866/2223 [00:49<01:16, 17.67it/s]\u001b[A\nSTL Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 868/2223 [00:49<01:14, 18.23it/s]\u001b[A\nSTL Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 870/2223 [00:50<01:12, 18.63it/s]\u001b[A\nSTL Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 872/2223 [00:50<01:18, 17.20it/s]\u001b[A\nSTL Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 874/2223 [00:50<01:16, 17.57it/s]\u001b[A\nSTL Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 876/2223 [00:50<01:14, 18.14it/s]\u001b[A\nSTL Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 878/2223 [00:50<01:12, 18.59it/s]\u001b[A\nSTL Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñâ      | 880/2223 [00:50<01:17, 17.33it/s]\u001b[A\nSTL Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñâ      | 882/2223 [00:50<01:15, 17.68it/s]\u001b[A\nSTL Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñâ      | 884/2223 [00:50<01:13, 18.25it/s]\u001b[A\nSTL Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñâ      | 886/2223 [00:50<01:11, 18.59it/s]\u001b[A\nSTL Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñâ      | 888/2223 [00:51<01:17, 17.29it/s]\u001b[A\nSTL Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñà      | 890/2223 [00:51<01:15, 17.57it/s]\u001b[A\nSTL Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñà      | 892/2223 [00:51<01:13, 18.15it/s]\u001b[A\nSTL Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñà      | 894/2223 [00:51<01:11, 18.56it/s]\u001b[A\nSTL Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñà      | 896/2223 [00:51<01:16, 17.26it/s]\u001b[A\nSTL Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñà      | 898/2223 [00:51<01:15, 17.62it/s]\u001b[A\nSTL Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñà      | 900/2223 [00:51<01:12, 18.20it/s]\u001b[A\nSTL Epoch 1:  41%|‚ñà‚ñà‚ñà‚ñà      | 902/2223 [00:51<01:10, 18.63it/s]\u001b[A\nSTL Epoch 1:  41%|‚ñà‚ñà‚ñà‚ñà      | 904/2223 [00:51<01:16, 17.34it/s]\u001b[A\nSTL Epoch 1:  41%|‚ñà‚ñà‚ñà‚ñà      | 906/2223 [00:52<01:14, 17.66it/s]\u001b[A\nSTL Epoch 1:  41%|‚ñà‚ñà‚ñà‚ñà      | 908/2223 [00:52<01:12, 18.16it/s]\u001b[A\nSTL Epoch 1:  41%|‚ñà‚ñà‚ñà‚ñà      | 910/2223 [00:52<01:10, 18.60it/s]\u001b[A\nSTL Epoch 1:  41%|‚ñà‚ñà‚ñà‚ñà      | 912/2223 [00:52<01:15, 17.29it/s]\u001b[A\nSTL Epoch 1:  41%|‚ñà‚ñà‚ñà‚ñà      | 914/2223 [00:52<01:14, 17.48it/s]\u001b[A\nSTL Epoch 1:  41%|‚ñà‚ñà‚ñà‚ñà      | 916/2223 [00:52<01:12, 18.09it/s]\u001b[A\nSTL Epoch 1:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 918/2223 [00:52<01:12, 18.00it/s]\u001b[A\nSTL Epoch 1:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 920/2223 [00:52<01:17, 16.89it/s]\u001b[A\nSTL Epoch 1:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 922/2223 [00:53<01:15, 17.27it/s]\u001b[A\nSTL Epoch 1:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 924/2223 [00:53<01:12, 17.94it/s]\u001b[A\nSTL Epoch 1:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 926/2223 [00:53<01:10, 18.35it/s]\u001b[A\nSTL Epoch 1:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 928/2223 [00:53<01:15, 17.14it/s]\u001b[A\nSTL Epoch 1:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 930/2223 [00:53<01:13, 17.50it/s]\u001b[A\nSTL Epoch 1:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 932/2223 [00:53<01:11, 18.08it/s]\u001b[A\nSTL Epoch 1:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 934/2223 [00:53<01:09, 18.53it/s]\u001b[A\nSTL Epoch 1:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 936/2223 [00:53<01:14, 17.24it/s]\u001b[A\nSTL Epoch 1:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 938/2223 [00:53<01:13, 17.60it/s]\u001b[A\nSTL Epoch 1:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 940/2223 [00:54<01:10, 18.08it/s]\u001b[A\nSTL Epoch 1:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 942/2223 [00:54<01:09, 18.55it/s]\u001b[A\nSTL Epoch 1:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 944/2223 [00:54<01:14, 17.19it/s]\u001b[A\nSTL Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 946/2223 [00:54<01:12, 17.58it/s]\u001b[A\nSTL Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 948/2223 [00:54<01:10, 18.16it/s]\u001b[A\nSTL Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 950/2223 [00:54<01:08, 18.58it/s]\u001b[A\nSTL Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 952/2223 [00:54<01:13, 17.27it/s]\u001b[A\nSTL Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 954/2223 [00:54<01:12, 17.59it/s]\u001b[A\nSTL Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 956/2223 [00:54<01:09, 18.11it/s]\u001b[A\nSTL Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 958/2223 [00:55<01:08, 18.43it/s]\u001b[A\nSTL Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 960/2223 [00:55<01:13, 17.21it/s]\u001b[A\nSTL Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 962/2223 [00:55<01:11, 17.55it/s]\u001b[A\nSTL Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 964/2223 [00:55<01:09, 18.15it/s]\u001b[A\nSTL Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 966/2223 [00:55<01:07, 18.57it/s]\u001b[A\nSTL Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 968/2223 [00:55<01:12, 17.27it/s]\u001b[A\nSTL Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 970/2223 [00:55<01:11, 17.64it/s]\u001b[A\nSTL Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 972/2223 [00:55<01:08, 18.21it/s]\u001b[A\nSTL Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 974/2223 [00:55<01:07, 18.55it/s]\u001b[A\nSTL Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 976/2223 [00:56<01:12, 17.19it/s]\u001b[A\nSTL Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 978/2223 [00:56<01:10, 17.55it/s]\u001b[A\nSTL Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 980/2223 [00:56<01:08, 18.15it/s]\u001b[A\nSTL Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 982/2223 [00:56<01:06, 18.56it/s]\u001b[A\nSTL Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 984/2223 [00:56<01:11, 17.26it/s]\u001b[A\nSTL Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 986/2223 [00:56<01:10, 17.58it/s]\u001b[A\nSTL Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 988/2223 [00:56<01:08, 18.15it/s]\u001b[A\nSTL Epoch 1:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 990/2223 [00:56<01:06, 18.57it/s]\u001b[A\nSTL Epoch 1:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 992/2223 [00:56<01:11, 17.24it/s]\u001b[A\nSTL Epoch 1:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 994/2223 [00:57<01:09, 17.56it/s]\u001b[A\nSTL Epoch 1:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 996/2223 [00:57<01:07, 18.10it/s]\u001b[A\nSTL Epoch 1:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 998/2223 [00:57<01:06, 18.53it/s]\u001b[A\nSTL Epoch 1:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 1000/2223 [00:57<01:11, 17.20it/s]\u001b[A\nSTL Epoch 1:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1002/2223 [00:57<01:09, 17.58it/s]\u001b[A\nSTL Epoch 1:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1004/2223 [00:57<01:07, 18.17it/s]\u001b[A\nSTL Epoch 1:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1006/2223 [00:57<01:05, 18.58it/s]\u001b[A\nSTL Epoch 1:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1008/2223 [00:57<01:10, 17.28it/s]\u001b[A\nSTL Epoch 1:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1010/2223 [00:57<01:08, 17.65it/s]\u001b[A\nSTL Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1012/2223 [00:58<01:06, 18.22it/s]\u001b[A\nSTL Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1014/2223 [00:58<01:04, 18.61it/s]\u001b[A\nSTL Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1016/2223 [00:58<01:11, 16.90it/s]\u001b[A\nSTL Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1018/2223 [00:58<01:10, 17.11it/s]\u001b[A\nSTL Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1020/2223 [00:58<01:07, 17.77it/s]\u001b[A\nSTL Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1022/2223 [00:58<01:05, 18.30it/s]\u001b[A\nSTL Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1024/2223 [00:58<01:10, 17.12it/s]\u001b[A\nSTL Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1026/2223 [00:58<01:08, 17.52it/s]\u001b[A\nSTL Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1028/2223 [00:58<01:05, 18.13it/s]\u001b[A\nSTL Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1030/2223 [00:59<01:04, 18.59it/s]\u001b[A\nSTL Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1032/2223 [00:59<01:09, 17.25it/s]\u001b[A\nSTL Epoch 1:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1034/2223 [00:59<01:07, 17.59it/s]\u001b[A\nSTL Epoch 1:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1036/2223 [00:59<01:05, 18.17it/s]\u001b[A\nSTL Epoch 1:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1038/2223 [00:59<01:03, 18.58it/s]\u001b[A\nSTL Epoch 1:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1040/2223 [00:59<01:08, 17.27it/s]\u001b[A\nSTL Epoch 1:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1042/2223 [00:59<01:06, 17.63it/s]\u001b[A\nSTL Epoch 1:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1044/2223 [00:59<01:04, 18.20it/s]\u001b[A\nSTL Epoch 1:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1046/2223 [00:59<01:03, 18.58it/s]\u001b[A\nSTL Epoch 1:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1048/2223 [01:00<01:08, 17.11it/s]\u001b[A\nSTL Epoch 1:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1050/2223 [01:00<01:09, 16.88it/s]\u001b[A\nSTL Epoch 1:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1052/2223 [01:00<01:08, 17.14it/s]\u001b[A\nSTL Epoch 1:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1054/2223 [01:00<01:07, 17.24it/s]\u001b[A\nSTL Epoch 1:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1056/2223 [01:00<01:13, 15.88it/s]\u001b[A\nSTL Epoch 1:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1058/2223 [01:00<01:12, 15.98it/s]\u001b[A\nSTL Epoch 1:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1060/2223 [01:00<01:10, 16.60it/s]\u001b[A\nSTL Epoch 1:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1062/2223 [01:00<01:08, 17.03it/s]\u001b[A\nSTL Epoch 1:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1064/2223 [01:01<01:11, 16.14it/s]\u001b[A\nSTL Epoch 1:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1066/2223 [01:01<01:09, 16.70it/s]\u001b[A\nSTL Epoch 1:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1068/2223 [01:01<01:06, 17.44it/s]\u001b[A\nSTL Epoch 1:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1070/2223 [01:01<01:04, 17.90it/s]\u001b[A\nSTL Epoch 1:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1072/2223 [01:01<01:09, 16.66it/s]\u001b[A\nSTL Epoch 1:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1074/2223 [01:01<01:06, 17.17it/s]\u001b[A\nSTL Epoch 1:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1076/2223 [01:01<01:04, 17.81it/s]\u001b[A\nSTL Epoch 1:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1078/2223 [01:01<01:02, 18.31it/s]\u001b[A\nSTL Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1080/2223 [01:01<01:06, 17.11it/s]\u001b[A\nSTL Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 1082/2223 [01:02<01:05, 17.43it/s]\u001b[A\nSTL Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1084/2223 [01:02<01:03, 18.04it/s]\u001b[A\nSTL Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1086/2223 [01:02<01:01, 18.43it/s]\u001b[A\nSTL Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1088/2223 [01:02<01:06, 17.12it/s]\u001b[A\nSTL Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1090/2223 [01:02<01:05, 17.22it/s]\u001b[A\nSTL Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1092/2223 [01:02<01:03, 17.86it/s]\u001b[A\nSTL Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1094/2223 [01:02<01:03, 17.73it/s]\u001b[A\nSTL Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1096/2223 [01:02<01:07, 16.72it/s]\u001b[A\nSTL Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1098/2223 [01:02<01:05, 17.17it/s]\u001b[A\nSTL Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1100/2223 [01:03<01:02, 17.84it/s]\u001b[A\nSTL Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1102/2223 [01:03<01:01, 18.32it/s]\u001b[A\nSTL Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1104/2223 [01:03<01:05, 17.02it/s]\u001b[A\nSTL Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1106/2223 [01:03<01:04, 17.43it/s]\u001b[A\nSTL Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1108/2223 [01:03<01:01, 17.99it/s]\u001b[A\nSTL Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1110/2223 [01:03<01:00, 18.45it/s]\u001b[A\nSTL Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1112/2223 [01:03<01:04, 17.10it/s]\u001b[A\nSTL Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1114/2223 [01:03<01:03, 17.49it/s]\u001b[A\nSTL Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1116/2223 [01:03<01:01, 18.06it/s]\u001b[A\nSTL Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1118/2223 [01:04<00:59, 18.46it/s]\u001b[A\nSTL Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1120/2223 [01:04<01:04, 17.16it/s]\u001b[A\nSTL Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1122/2223 [01:04<01:02, 17.52it/s]\u001b[A\nSTL Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1124/2223 [01:04<01:00, 18.07it/s]\u001b[A\nSTL Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1126/2223 [01:04<00:59, 18.47it/s]\u001b[A\nSTL Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1128/2223 [01:04<01:03, 17.11it/s]\u001b[A\nSTL Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1130/2223 [01:04<01:02, 17.48it/s]\u001b[A\nSTL Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1132/2223 [01:04<01:00, 18.02it/s]\u001b[A\nSTL Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1134/2223 [01:04<00:59, 18.45it/s]\u001b[A\nSTL Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1136/2223 [01:05<01:03, 17.14it/s]\u001b[A\nSTL Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1138/2223 [01:05<01:02, 17.50it/s]\u001b[A\nSTL Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1140/2223 [01:05<01:00, 18.02it/s]\u001b[A\nSTL Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1142/2223 [01:05<00:58, 18.45it/s]\u001b[A\nSTL Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1144/2223 [01:05<01:02, 17.13it/s]\u001b[A\nSTL Epoch 1:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1146/2223 [01:05<01:01, 17.54it/s]\u001b[A\nSTL Epoch 1:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1148/2223 [01:05<00:59, 18.14it/s]\u001b[A\nSTL Epoch 1:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1150/2223 [01:05<00:57, 18.57it/s]\u001b[A\nSTL Epoch 1:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1152/2223 [01:06<01:02, 17.19it/s]\u001b[A\nSTL Epoch 1:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1154/2223 [01:06<01:00, 17.54it/s]\u001b[A\nSTL Epoch 1:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1156/2223 [01:06<00:58, 18.09it/s]\u001b[A\nSTL Epoch 1:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1158/2223 [01:06<00:57, 18.53it/s]\u001b[A\nSTL Epoch 1:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1160/2223 [01:06<01:01, 17.21it/s]\u001b[A\nSTL Epoch 1:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1162/2223 [01:06<01:00, 17.60it/s]\u001b[A\nSTL Epoch 1:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1164/2223 [01:06<00:58, 18.17it/s]\u001b[A\nSTL Epoch 1:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1166/2223 [01:06<00:56, 18.61it/s]\u001b[A\nSTL Epoch 1:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1168/2223 [01:06<01:01, 17.23it/s]\u001b[A\nSTL Epoch 1:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1170/2223 [01:07<01:00, 17.50it/s]\u001b[A\nSTL Epoch 1:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1172/2223 [01:07<00:58, 18.07it/s]\u001b[A\nSTL Epoch 1:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1174/2223 [01:07<00:56, 18.51it/s]\u001b[A\nSTL Epoch 1:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1176/2223 [01:07<01:00, 17.22it/s]\u001b[A\nSTL Epoch 1:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1178/2223 [01:07<00:59, 17.61it/s]\u001b[A\nSTL Epoch 1:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1180/2223 [01:07<00:57, 18.16it/s]\u001b[A\nSTL Epoch 1:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1182/2223 [01:07<00:56, 18.57it/s]\u001b[A\nSTL Epoch 1:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1184/2223 [01:07<01:00, 17.25it/s]\u001b[A\nSTL Epoch 1:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1186/2223 [01:07<00:58, 17.62it/s]\u001b[A\nSTL Epoch 1:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1188/2223 [01:08<00:57, 18.08it/s]\u001b[A\nSTL Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1190/2223 [01:08<00:55, 18.53it/s]\u001b[A\nSTL Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1192/2223 [01:08<01:00, 17.14it/s]\u001b[A\nSTL Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1194/2223 [01:08<00:58, 17.48it/s]\u001b[A\nSTL Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1196/2223 [01:08<00:56, 18.03it/s]\u001b[A\nSTL Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1198/2223 [01:08<00:55, 18.33it/s]\u001b[A\nSTL Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1200/2223 [01:08<01:00, 17.01it/s]\u001b[A\nSTL Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1202/2223 [01:08<00:58, 17.42it/s]\u001b[A\nSTL Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1204/2223 [01:08<00:56, 17.96it/s]\u001b[A\nSTL Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1206/2223 [01:09<00:55, 18.33it/s]\u001b[A\nSTL Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1208/2223 [01:09<00:59, 16.94it/s]\u001b[A\nSTL Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1210/2223 [01:09<00:58, 17.33it/s]\u001b[A\nSTL Epoch 1:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1212/2223 [01:09<00:56, 17.90it/s]\u001b[A\nSTL Epoch 1:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1214/2223 [01:09<00:55, 18.29it/s]\u001b[A\nSTL Epoch 1:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1216/2223 [01:09<00:59, 16.96it/s]\u001b[A\nSTL Epoch 1:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1218/2223 [01:09<00:58, 17.32it/s]\u001b[A\nSTL Epoch 1:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1220/2223 [01:09<00:56, 17.91it/s]\u001b[A\nSTL Epoch 1:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 1222/2223 [01:09<00:54, 18.34it/s]\u001b[A\nSTL Epoch 1:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1224/2223 [01:10<00:58, 16.95it/s]\u001b[A\nSTL Epoch 1:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1226/2223 [01:10<00:57, 17.34it/s]\u001b[A\nSTL Epoch 1:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1228/2223 [01:10<00:55, 17.94it/s]\u001b[A\nSTL Epoch 1:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1230/2223 [01:10<00:53, 18.41it/s]\u001b[A\nSTL Epoch 1:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1232/2223 [01:10<00:57, 17.11it/s]\u001b[A\nSTL Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1234/2223 [01:10<00:56, 17.54it/s]\u001b[A\nSTL Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1236/2223 [01:10<00:54, 18.11it/s]\u001b[A\nSTL Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1238/2223 [01:10<00:53, 18.55it/s]\u001b[A\nSTL Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1240/2223 [01:10<00:57, 17.16it/s]\u001b[A\nSTL Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1242/2223 [01:11<00:55, 17.55it/s]\u001b[A\nSTL Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1244/2223 [01:11<00:54, 18.08it/s]\u001b[A\nSTL Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1246/2223 [01:11<00:52, 18.53it/s]\u001b[A\nSTL Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1248/2223 [01:11<00:57, 17.10it/s]\u001b[A\nSTL Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1250/2223 [01:11<00:55, 17.42it/s]\u001b[A\nSTL Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1252/2223 [01:11<00:53, 17.99it/s]\u001b[A\nSTL Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1254/2223 [01:11<00:52, 18.39it/s]\u001b[A\nSTL Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1256/2223 [01:11<00:56, 17.03it/s]\u001b[A\nSTL Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1258/2223 [01:11<00:55, 17.40it/s]\u001b[A\nSTL Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1260/2223 [01:12<00:53, 17.97it/s]\u001b[A\nSTL Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1262/2223 [01:12<00:52, 18.41it/s]\u001b[A\nSTL Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1264/2223 [01:12<00:56, 17.03it/s]\u001b[A\nSTL Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1266/2223 [01:12<00:54, 17.43it/s]\u001b[A\nSTL Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1268/2223 [01:12<00:54, 17.53it/s]\u001b[A\nSTL Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1270/2223 [01:12<00:53, 17.68it/s]\u001b[A\nSTL Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1272/2223 [01:12<00:57, 16.64it/s]\u001b[A\nSTL Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1274/2223 [01:12<00:55, 17.17it/s]\u001b[A\nSTL Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1276/2223 [01:13<00:53, 17.84it/s]\u001b[A\nSTL Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 1278/2223 [01:13<00:51, 18.30it/s]\u001b[A\nSTL Epoch 1:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1280/2223 [01:13<00:55, 17.03it/s]\u001b[A\nSTL Epoch 1:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1282/2223 [01:13<00:53, 17.47it/s]\u001b[A\nSTL Epoch 1:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1284/2223 [01:13<00:52, 17.98it/s]\u001b[A\nSTL Epoch 1:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1286/2223 [01:13<00:50, 18.42it/s]\u001b[A\nSTL Epoch 1:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1288/2223 [01:13<00:54, 17.07it/s]\u001b[A\nSTL Epoch 1:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1290/2223 [01:13<00:53, 17.48it/s]\u001b[A\nSTL Epoch 1:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1292/2223 [01:13<00:51, 17.98it/s]\u001b[A\nSTL Epoch 1:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1294/2223 [01:14<00:50, 18.40it/s]\u001b[A\nSTL Epoch 1:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1296/2223 [01:14<00:54, 17.06it/s]\u001b[A\nSTL Epoch 1:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1298/2223 [01:14<00:52, 17.46it/s]\u001b[A\nSTL Epoch 1:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1300/2223 [01:14<00:51, 18.07it/s]\u001b[A\nSTL Epoch 1:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1302/2223 [01:14<00:49, 18.46it/s]\u001b[A\nSTL Epoch 1:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1304/2223 [01:14<00:53, 17.09it/s]\u001b[A\nSTL Epoch 1:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1306/2223 [01:14<00:52, 17.49it/s]\u001b[A\nSTL Epoch 1:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1308/2223 [01:14<00:50, 18.05it/s]\u001b[A\nSTL Epoch 1:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1310/2223 [01:14<00:49, 18.50it/s]\u001b[A\nSTL Epoch 1:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1312/2223 [01:15<00:53, 17.10it/s]\u001b[A\nSTL Epoch 1:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1314/2223 [01:15<00:52, 17.43it/s]\u001b[A\nSTL Epoch 1:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1316/2223 [01:15<00:50, 17.96it/s]\u001b[A\nSTL Epoch 1:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1318/2223 [01:15<00:49, 18.42it/s]\u001b[A\nSTL Epoch 1:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1320/2223 [01:15<00:53, 17.02it/s]\u001b[A\nSTL Epoch 1:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1322/2223 [01:15<00:51, 17.43it/s]\u001b[A\nSTL Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1324/2223 [01:15<00:49, 17.99it/s]\u001b[A\nSTL Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1326/2223 [01:15<00:48, 18.39it/s]\u001b[A\nSTL Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1328/2223 [01:15<00:52, 17.02it/s]\u001b[A\nSTL Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1330/2223 [01:16<00:51, 17.35it/s]\u001b[A\nSTL Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1332/2223 [01:16<00:49, 17.89it/s]\u001b[A\nSTL Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1334/2223 [01:16<00:48, 18.38it/s]\u001b[A\nSTL Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1336/2223 [01:16<00:52, 16.95it/s]\u001b[A\nSTL Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1338/2223 [01:16<00:51, 17.35it/s]\u001b[A\nSTL Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1340/2223 [01:16<00:49, 17.91it/s]\u001b[A\nSTL Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1342/2223 [01:16<00:48, 18.33it/s]\u001b[A\nSTL Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1344/2223 [01:16<00:51, 17.00it/s]\u001b[A\nSTL Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1346/2223 [01:16<00:50, 17.41it/s]\u001b[A\nSTL Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1348/2223 [01:17<00:48, 17.98it/s]\u001b[A\nSTL Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1350/2223 [01:17<00:47, 18.45it/s]\u001b[A\nSTL Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1352/2223 [01:17<00:50, 17.08it/s]\u001b[A\nSTL Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1354/2223 [01:17<00:49, 17.49it/s]\u001b[A\nSTL Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1356/2223 [01:17<00:48, 18.05it/s]\u001b[A\nSTL Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1358/2223 [01:17<00:46, 18.48it/s]\u001b[A\nSTL Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1360/2223 [01:17<00:50, 17.14it/s]\u001b[A\nSTL Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1362/2223 [01:17<00:48, 17.58it/s]\u001b[A\nSTL Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1364/2223 [01:17<00:47, 18.10it/s]\u001b[A\nSTL Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1366/2223 [01:18<00:46, 18.50it/s]\u001b[A\nSTL Epoch 1:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1368/2223 [01:18<00:49, 17.12it/s]\u001b[A\nSTL Epoch 1:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1370/2223 [01:18<00:48, 17.48it/s]\u001b[A\nSTL Epoch 1:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1372/2223 [01:18<00:47, 17.89it/s]\u001b[A\nSTL Epoch 1:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1374/2223 [01:18<00:46, 18.28it/s]\u001b[A\nSTL Epoch 1:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1376/2223 [01:18<00:49, 16.95it/s]\u001b[A\nSTL Epoch 1:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1378/2223 [01:18<00:48, 17.39it/s]\u001b[A\nSTL Epoch 1:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1380/2223 [01:18<00:47, 17.93it/s]\u001b[A\nSTL Epoch 1:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1382/2223 [01:18<00:45, 18.37it/s]\u001b[A\nSTL Epoch 1:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1384/2223 [01:19<00:49, 17.05it/s]\u001b[A\nSTL Epoch 1:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1386/2223 [01:19<00:48, 17.41it/s]\u001b[A\nSTL Epoch 1:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1388/2223 [01:19<00:46, 17.95it/s]\u001b[A\nSTL Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1390/2223 [01:19<00:45, 18.34it/s]\u001b[A\nSTL Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1392/2223 [01:19<00:49, 16.96it/s]\u001b[A\nSTL Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1394/2223 [01:19<00:47, 17.36it/s]\u001b[A\nSTL Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1396/2223 [01:19<00:46, 17.89it/s]\u001b[A\nSTL Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1398/2223 [01:19<00:45, 18.31it/s]\u001b[A\nSTL Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1400/2223 [01:20<00:48, 16.98it/s]\u001b[A\nSTL Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1402/2223 [01:20<00:47, 17.38it/s]\u001b[A\nSTL Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1404/2223 [01:20<00:45, 17.90it/s]\u001b[A\nSTL Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1406/2223 [01:20<00:44, 18.37it/s]\u001b[A\nSTL Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1408/2223 [01:20<00:47, 17.05it/s]\u001b[A\nSTL Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1410/2223 [01:20<00:46, 17.49it/s]\u001b[A\nSTL Epoch 1:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1412/2223 [01:20<00:44, 18.03it/s]\u001b[A\nSTL Epoch 1:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1414/2223 [01:20<00:43, 18.41it/s]\u001b[A\nSTL Epoch 1:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 1416/2223 [01:20<00:47, 17.02it/s]\u001b[A\nSTL Epoch 1:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1418/2223 [01:21<00:46, 17.34it/s]\u001b[A\nSTL Epoch 1:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1420/2223 [01:21<00:44, 17.88it/s]\u001b[A\nSTL Epoch 1:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1422/2223 [01:21<00:43, 18.30it/s]\u001b[A\nSTL Epoch 1:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1424/2223 [01:21<00:47, 16.98it/s]\u001b[A\nSTL Epoch 1:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1426/2223 [01:21<00:45, 17.43it/s]\u001b[A\nSTL Epoch 1:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1428/2223 [01:21<00:44, 17.97it/s]\u001b[A\nSTL Epoch 1:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1430/2223 [01:21<00:43, 18.40it/s]\u001b[A\nSTL Epoch 1:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1432/2223 [01:21<00:46, 17.09it/s]\u001b[A\nSTL Epoch 1:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1434/2223 [01:21<00:45, 17.53it/s]\u001b[A\nSTL Epoch 1:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1436/2223 [01:22<00:43, 17.96it/s]\u001b[A\nSTL Epoch 1:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1438/2223 [01:22<00:42, 18.33it/s]\u001b[A\nSTL Epoch 1:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1440/2223 [01:22<00:46, 16.93it/s]\u001b[A\nSTL Epoch 1:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1442/2223 [01:22<00:45, 17.35it/s]\u001b[A\nSTL Epoch 1:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1444/2223 [01:22<00:44, 17.52it/s]\u001b[A\nSTL Epoch 1:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1446/2223 [01:22<00:42, 18.08it/s]\u001b[A\nSTL Epoch 1:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1448/2223 [01:22<00:47, 16.27it/s]\u001b[A\nSTL Epoch 1:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1450/2223 [01:22<00:45, 16.89it/s]\u001b[A\nSTL Epoch 1:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1452/2223 [01:22<00:43, 17.56it/s]\u001b[A\nSTL Epoch 1:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1454/2223 [01:23<00:42, 18.10it/s]\u001b[A\nSTL Epoch 1:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1456/2223 [01:23<00:45, 16.88it/s]\u001b[A\nSTL Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1458/2223 [01:23<00:44, 17.31it/s]\u001b[A\nSTL Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1460/2223 [01:23<00:42, 17.89it/s]\u001b[A\nSTL Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1462/2223 [01:23<00:41, 18.32it/s]\u001b[A\nSTL Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1464/2223 [01:23<00:44, 16.87it/s]\u001b[A\nSTL Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1466/2223 [01:23<00:43, 17.35it/s]\u001b[A\nSTL Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1468/2223 [01:23<00:42, 17.91it/s]\u001b[A\nSTL Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1470/2223 [01:23<00:41, 18.33it/s]\u001b[A\nSTL Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1472/2223 [01:24<00:44, 16.96it/s]\u001b[A\nSTL Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1474/2223 [01:24<00:43, 17.33it/s]\u001b[A\nSTL Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1476/2223 [01:24<00:41, 17.84it/s]\u001b[A\nSTL Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1478/2223 [01:24<00:40, 18.23it/s]\u001b[A\nSTL Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1480/2223 [01:24<00:44, 16.76it/s]\u001b[A\nSTL Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1482/2223 [01:24<00:43, 17.22it/s]\u001b[A\nSTL Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1484/2223 [01:24<00:41, 17.83it/s]\u001b[A\nSTL Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1486/2223 [01:24<00:40, 18.27it/s]\u001b[A\nSTL Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1488/2223 [01:25<00:43, 16.95it/s]\u001b[A\nSTL Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1490/2223 [01:25<00:42, 17.28it/s]\u001b[A\nSTL Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1492/2223 [01:25<00:40, 17.84it/s]\u001b[A\nSTL Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1494/2223 [01:25<00:40, 18.22it/s]\u001b[A\nSTL Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1496/2223 [01:25<00:43, 16.81it/s]\u001b[A\nSTL Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1498/2223 [01:25<00:41, 17.28it/s]\u001b[A\nSTL Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1500/2223 [01:25<00:40, 17.85it/s]\u001b[A\nSTL Epoch 1:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1502/2223 [01:25<00:39, 18.27it/s]\u001b[A\nSTL Epoch 1:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1504/2223 [01:25<00:42, 16.97it/s]\u001b[A\nSTL Epoch 1:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1506/2223 [01:26<00:41, 17.21it/s]\u001b[A\nSTL Epoch 1:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1508/2223 [01:26<00:40, 17.75it/s]\u001b[A\nSTL Epoch 1:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1510/2223 [01:26<00:39, 18.14it/s]\u001b[A\nSTL Epoch 1:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1512/2223 [01:26<00:42, 16.81it/s]\u001b[A\nSTL Epoch 1:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1514/2223 [01:26<00:41, 17.26it/s]\u001b[A\nSTL Epoch 1:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1516/2223 [01:26<00:39, 17.83it/s]\u001b[A\nSTL Epoch 1:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1518/2223 [01:26<00:38, 18.26it/s]\u001b[A\nSTL Epoch 1:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1520/2223 [01:26<00:41, 16.91it/s]\u001b[A\nSTL Epoch 1:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1522/2223 [01:26<00:40, 17.27it/s]\u001b[A\nSTL Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1524/2223 [01:27<00:39, 17.79it/s]\u001b[A\nSTL Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1526/2223 [01:27<00:38, 18.20it/s]\u001b[A\nSTL Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1528/2223 [01:27<00:41, 16.89it/s]\u001b[A\nSTL Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1530/2223 [01:27<00:40, 17.31it/s]\u001b[A\nSTL Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1532/2223 [01:27<00:38, 17.88it/s]\u001b[A\nSTL Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1534/2223 [01:27<00:37, 18.30it/s]\u001b[A\nSTL Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1536/2223 [01:27<00:40, 16.96it/s]\u001b[A\nSTL Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1538/2223 [01:27<00:39, 17.36it/s]\u001b[A\nSTL Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1540/2223 [01:28<00:38, 17.86it/s]\u001b[A\nSTL Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1542/2223 [01:28<00:37, 18.18it/s]\u001b[A\nSTL Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1544/2223 [01:28<00:40, 16.84it/s]\u001b[A\nSTL Epoch 1:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1546/2223 [01:28<00:39, 17.29it/s]\u001b[A\nSTL Epoch 1:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1548/2223 [01:28<00:37, 17.83it/s]\u001b[A\nSTL Epoch 1:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1550/2223 [01:28<00:36, 18.30it/s]\u001b[A\nSTL Epoch 1:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1552/2223 [01:28<00:39, 16.90it/s]\u001b[A\nSTL Epoch 1:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1554/2223 [01:28<00:38, 17.35it/s]\u001b[A\nSTL Epoch 1:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 1556/2223 [01:28<00:37, 17.92it/s]\u001b[A\nSTL Epoch 1:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1558/2223 [01:29<00:36, 18.25it/s]\u001b[A\nSTL Epoch 1:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1560/2223 [01:29<00:39, 16.83it/s]\u001b[A\nSTL Epoch 1:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1562/2223 [01:29<00:38, 17.22it/s]\u001b[A\nSTL Epoch 1:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1564/2223 [01:29<00:37, 17.80it/s]\u001b[A\nSTL Epoch 1:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1566/2223 [01:29<00:35, 18.27it/s]\u001b[A\nSTL Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1568/2223 [01:29<00:38, 16.83it/s]\u001b[A\nSTL Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1570/2223 [01:29<00:37, 17.28it/s]\u001b[A\nSTL Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1572/2223 [01:29<00:36, 17.84it/s]\u001b[A\nSTL Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1574/2223 [01:29<00:35, 18.24it/s]\u001b[A\nSTL Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1576/2223 [01:30<00:38, 16.86it/s]\u001b[A\nSTL Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1578/2223 [01:30<00:37, 17.27it/s]\u001b[A\nSTL Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1580/2223 [01:30<00:36, 17.80it/s]\u001b[A\nSTL Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1582/2223 [01:30<00:35, 18.25it/s]\u001b[A\nSTL Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1584/2223 [01:30<00:37, 16.89it/s]\u001b[A\nSTL Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1586/2223 [01:30<00:36, 17.31it/s]\u001b[A\nSTL Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1588/2223 [01:30<00:35, 17.81it/s]\u001b[A\nSTL Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1590/2223 [01:30<00:34, 18.22it/s]\u001b[A\nSTL Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1592/2223 [01:30<00:37, 16.79it/s]\u001b[A\nSTL Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1594/2223 [01:31<00:36, 17.13it/s]\u001b[A\nSTL Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1596/2223 [01:31<00:35, 17.66it/s]\u001b[A\nSTL Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1598/2223 [01:31<00:34, 18.00it/s]\u001b[A\nSTL Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1600/2223 [01:31<00:37, 16.66it/s]\u001b[A\nSTL Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1602/2223 [01:31<00:36, 17.12it/s]\u001b[A\nSTL Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1604/2223 [01:31<00:36, 16.74it/s]\u001b[A\nSTL Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1606/2223 [01:31<00:35, 17.36it/s]\u001b[A\nSTL Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1608/2223 [01:31<00:38, 16.12it/s]\u001b[A\nSTL Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1610/2223 [01:32<00:38, 16.06it/s]\u001b[A\nSTL Epoch 1:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1612/2223 [01:32<00:37, 16.43it/s]\u001b[A\nSTL Epoch 1:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1614/2223 [01:32<00:35, 17.17it/s]\u001b[A\nSTL Epoch 1:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1616/2223 [01:32<00:38, 15.94it/s]\u001b[A\nSTL Epoch 1:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1618/2223 [01:32<00:37, 16.17it/s]\u001b[A\nSTL Epoch 1:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1620/2223 [01:32<00:36, 16.39it/s]\u001b[A\nSTL Epoch 1:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1622/2223 [01:32<00:35, 16.80it/s]\u001b[A\nSTL Epoch 1:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1624/2223 [01:32<00:37, 15.92it/s]\u001b[A\nSTL Epoch 1:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1626/2223 [01:33<00:36, 16.52it/s]\u001b[A\nSTL Epoch 1:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1628/2223 [01:33<00:34, 17.21it/s]\u001b[A\nSTL Epoch 1:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1630/2223 [01:33<00:33, 17.75it/s]\u001b[A\nSTL Epoch 1:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1632/2223 [01:33<00:35, 16.57it/s]\u001b[A\nSTL Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1634/2223 [01:33<00:34, 17.14it/s]\u001b[A\nSTL Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1636/2223 [01:33<00:33, 17.70it/s]\u001b[A\nSTL Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1638/2223 [01:33<00:32, 18.21it/s]\u001b[A\nSTL Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1640/2223 [01:33<00:34, 16.86it/s]\u001b[A\nSTL Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1642/2223 [01:33<00:33, 17.29it/s]\u001b[A\nSTL Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1644/2223 [01:34<00:32, 17.82it/s]\u001b[A\nSTL Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1646/2223 [01:34<00:31, 18.16it/s]\u001b[A\nSTL Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1648/2223 [01:34<00:34, 16.78it/s]\u001b[A\nSTL Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1650/2223 [01:34<00:33, 17.21it/s]\u001b[A\nSTL Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1652/2223 [01:34<00:32, 17.77it/s]\u001b[A\nSTL Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1654/2223 [01:34<00:31, 17.93it/s]\u001b[A\nSTL Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1656/2223 [01:34<00:34, 16.54it/s]\u001b[A\nSTL Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1658/2223 [01:34<00:33, 17.08it/s]\u001b[A\nSTL Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1660/2223 [01:34<00:31, 17.64it/s]\u001b[A\nSTL Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1662/2223 [01:35<00:30, 18.14it/s]\u001b[A\nSTL Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1664/2223 [01:35<00:33, 16.73it/s]\u001b[A\nSTL Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1666/2223 [01:35<00:32, 17.19it/s]\u001b[A\nSTL Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1668/2223 [01:35<00:31, 17.71it/s]\u001b[A\nSTL Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1670/2223 [01:35<00:30, 18.10it/s]\u001b[A\nSTL Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1672/2223 [01:35<00:32, 16.74it/s]\u001b[A\nSTL Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1674/2223 [01:35<00:31, 17.26it/s]\u001b[A\nSTL Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1676/2223 [01:35<00:30, 17.84it/s]\u001b[A\nSTL Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1678/2223 [01:35<00:29, 18.21it/s]\u001b[A\nSTL Epoch 1:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1680/2223 [01:36<00:32, 16.71it/s]\u001b[A\nSTL Epoch 1:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1682/2223 [01:36<00:31, 17.18it/s]\u001b[A\nSTL Epoch 1:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1684/2223 [01:36<00:30, 17.69it/s]\u001b[A\nSTL Epoch 1:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1686/2223 [01:36<00:29, 18.14it/s]\u001b[A\nSTL Epoch 1:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1688/2223 [01:36<00:31, 16.74it/s]\u001b[A\nSTL Epoch 1:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1690/2223 [01:36<00:31, 17.17it/s]\u001b[A\nSTL Epoch 1:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1692/2223 [01:36<00:30, 17.68it/s]\u001b[A\nSTL Epoch 1:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1694/2223 [01:36<00:29, 18.09it/s]\u001b[A\nSTL Epoch 1:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1696/2223 [01:37<00:31, 16.71it/s]\u001b[A\nSTL Epoch 1:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1698/2223 [01:37<00:30, 17.20it/s]\u001b[A\nSTL Epoch 1:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1700/2223 [01:37<00:29, 17.75it/s]\u001b[A\nSTL Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1702/2223 [01:37<00:28, 18.13it/s]\u001b[A\nSTL Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1704/2223 [01:37<00:31, 16.69it/s]\u001b[A\nSTL Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1706/2223 [01:37<00:30, 17.19it/s]\u001b[A\nSTL Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1708/2223 [01:37<00:29, 17.72it/s]\u001b[A\nSTL Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1710/2223 [01:37<00:28, 18.17it/s]\u001b[A\nSTL Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1712/2223 [01:37<00:30, 16.74it/s]\u001b[A\nSTL Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1714/2223 [01:38<00:29, 17.20it/s]\u001b[A\nSTL Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1716/2223 [01:38<00:28, 17.67it/s]\u001b[A\nSTL Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1718/2223 [01:38<00:27, 18.14it/s]\u001b[A\nSTL Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1720/2223 [01:38<00:29, 16.79it/s]\u001b[A\nSTL Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1722/2223 [01:38<00:29, 17.17it/s]\u001b[A\nSTL Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1724/2223 [01:38<00:28, 17.75it/s]\u001b[A\nSTL Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1726/2223 [01:38<00:27, 18.15it/s]\u001b[A\nSTL Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1728/2223 [01:38<00:29, 16.69it/s]\u001b[A\nSTL Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1730/2223 [01:38<00:28, 17.19it/s]\u001b[A\nSTL Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1732/2223 [01:39<00:27, 17.71it/s]\u001b[A\nSTL Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1734/2223 [01:39<00:26, 18.18it/s]\u001b[A\nSTL Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1736/2223 [01:39<00:29, 16.73it/s]\u001b[A\nSTL Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1738/2223 [01:39<00:28, 17.17it/s]\u001b[A\nSTL Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1740/2223 [01:39<00:27, 17.67it/s]\u001b[A\nSTL Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1742/2223 [01:39<00:26, 18.14it/s]\u001b[A\nSTL Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1744/2223 [01:39<00:28, 16.77it/s]\u001b[A\nSTL Epoch 1:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1746/2223 [01:39<00:27, 17.22it/s]\u001b[A\nSTL Epoch 1:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1748/2223 [01:40<00:26, 17.74it/s]\u001b[A\nSTL Epoch 1:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1750/2223 [01:40<00:26, 18.09it/s]\u001b[A\nSTL Epoch 1:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1752/2223 [01:40<00:28, 16.72it/s]\u001b[A\nSTL Epoch 1:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1754/2223 [01:40<00:27, 17.23it/s]\u001b[A\nSTL Epoch 1:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1756/2223 [01:40<00:26, 17.75it/s]\u001b[A\nSTL Epoch 1:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1758/2223 [01:40<00:25, 18.11it/s]\u001b[A\nSTL Epoch 1:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1760/2223 [01:40<00:27, 16.62it/s]\u001b[A\nSTL Epoch 1:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1762/2223 [01:40<00:27, 17.00it/s]\u001b[A\nSTL Epoch 1:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1764/2223 [01:40<00:26, 17.53it/s]\u001b[A\nSTL Epoch 1:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1766/2223 [01:41<00:25, 17.96it/s]\u001b[A\nSTL Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1768/2223 [01:41<00:27, 16.50it/s]\u001b[A\nSTL Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1770/2223 [01:41<00:26, 16.98it/s]\u001b[A\nSTL Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1772/2223 [01:41<00:25, 17.57it/s]\u001b[A\nSTL Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1774/2223 [01:41<00:24, 18.06it/s]\u001b[A\nSTL Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1776/2223 [01:41<00:26, 16.63it/s]\u001b[A\nSTL Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1778/2223 [01:41<00:26, 17.09it/s]\u001b[A\nSTL Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1780/2223 [01:41<00:25, 17.59it/s]\u001b[A\nSTL Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1782/2223 [01:41<00:24, 18.04it/s]\u001b[A\nSTL Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1784/2223 [01:42<00:26, 16.68it/s]\u001b[A\nSTL Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1786/2223 [01:42<00:25, 17.16it/s]\u001b[A\nSTL Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1788/2223 [01:42<00:24, 17.73it/s]\u001b[A\nSTL Epoch 1:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1790/2223 [01:42<00:23, 18.09it/s]\u001b[A\nSTL Epoch 1:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1792/2223 [01:42<00:26, 16.40it/s]\u001b[A\nSTL Epoch 1:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1794/2223 [01:42<00:26, 16.48it/s]\u001b[A\nSTL Epoch 1:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1796/2223 [01:42<00:24, 17.25it/s]\u001b[A\nSTL Epoch 1:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1798/2223 [01:42<00:23, 17.76it/s]\u001b[A\nSTL Epoch 1:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1800/2223 [01:43<00:25, 16.41it/s]\u001b[A\nSTL Epoch 1:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1802/2223 [01:43<00:24, 16.95it/s]\u001b[A\nSTL Epoch 1:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1804/2223 [01:43<00:23, 17.53it/s]\u001b[A\nSTL Epoch 1:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1806/2223 [01:43<00:23, 18.01it/s]\u001b[A\nSTL Epoch 1:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1808/2223 [01:43<00:24, 16.67it/s]\u001b[A\nSTL Epoch 1:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1810/2223 [01:43<00:24, 17.14it/s]\u001b[A\nSTL Epoch 1:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1812/2223 [01:43<00:23, 17.69it/s]\u001b[A\nSTL Epoch 1:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1814/2223 [01:43<00:22, 18.07it/s]\u001b[A\nSTL Epoch 1:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1816/2223 [01:43<00:24, 16.69it/s]\u001b[A\nSTL Epoch 1:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1818/2223 [01:44<00:23, 17.17it/s]\u001b[A\nSTL Epoch 1:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1820/2223 [01:44<00:22, 17.68it/s]\u001b[A\nSTL Epoch 1:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1822/2223 [01:44<00:22, 18.08it/s]\u001b[A\nSTL Epoch 1:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1824/2223 [01:44<00:23, 16.65it/s]\u001b[A\nSTL Epoch 1:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1826/2223 [01:44<00:23, 17.12it/s]\u001b[A\nSTL Epoch 1:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1828/2223 [01:44<00:22, 17.68it/s]\u001b[A\nSTL Epoch 1:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1830/2223 [01:44<00:21, 18.10it/s]\u001b[A\nSTL Epoch 1:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1832/2223 [01:44<00:23, 16.65it/s]\u001b[A\nSTL Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1834/2223 [01:44<00:22, 17.11it/s]\u001b[A\nSTL Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1836/2223 [01:45<00:21, 17.65it/s]\u001b[A\nSTL Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1838/2223 [01:45<00:21, 18.09it/s]\u001b[A\nSTL Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1840/2223 [01:45<00:22, 16.71it/s]\u001b[A\nSTL Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1842/2223 [01:45<00:22, 17.21it/s]\u001b[A\nSTL Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1844/2223 [01:45<00:21, 17.75it/s]\u001b[A\nSTL Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1846/2223 [01:45<00:20, 18.13it/s]\u001b[A\nSTL Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1848/2223 [01:45<00:22, 16.69it/s]\u001b[A\nSTL Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1850/2223 [01:45<00:21, 17.23it/s]\u001b[A\nSTL Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1852/2223 [01:46<00:20, 17.77it/s]\u001b[A\nSTL Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1854/2223 [01:46<00:20, 18.11it/s]\u001b[A\nSTL Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1856/2223 [01:46<00:22, 16.61it/s]\u001b[A\nSTL Epoch 1:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1858/2223 [01:46<00:21, 17.11it/s]\u001b[A\nSTL Epoch 1:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1860/2223 [01:46<00:20, 17.66it/s]\u001b[A\nSTL Epoch 1:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1862/2223 [01:46<00:19, 18.15it/s]\u001b[A\nSTL Epoch 1:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1864/2223 [01:46<00:21, 16.79it/s]\u001b[A\nSTL Epoch 1:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1866/2223 [01:46<00:20, 17.23it/s]\u001b[A\nSTL Epoch 1:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1868/2223 [01:46<00:19, 17.78it/s]\u001b[A\nSTL Epoch 1:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1870/2223 [01:47<00:19, 18.14it/s]\u001b[A\nSTL Epoch 1:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1872/2223 [01:47<00:21, 16.69it/s]\u001b[A\nSTL Epoch 1:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1874/2223 [01:47<00:20, 17.16it/s]\u001b[A\nSTL Epoch 1:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1876/2223 [01:47<00:19, 17.72it/s]\u001b[A\nSTL Epoch 1:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1878/2223 [01:47<00:18, 18.16it/s]\u001b[A\nSTL Epoch 1:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1880/2223 [01:47<00:20, 16.67it/s]\u001b[A\nSTL Epoch 1:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1882/2223 [01:47<00:19, 17.17it/s]\u001b[A\nSTL Epoch 1:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1884/2223 [01:47<00:19, 17.76it/s]\u001b[A\nSTL Epoch 1:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1886/2223 [01:47<00:18, 18.20it/s]\u001b[A\nSTL Epoch 1:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1888/2223 [01:48<00:19, 16.79it/s]\u001b[A\nSTL Epoch 1:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1890/2223 [01:48<00:19, 17.24it/s]\u001b[A\nSTL Epoch 1:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1892/2223 [01:48<00:18, 17.77it/s]\u001b[A\nSTL Epoch 1:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1894/2223 [01:48<00:18, 18.11it/s]\u001b[A\nSTL Epoch 1:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1896/2223 [01:48<00:19, 16.68it/s]\u001b[A\nSTL Epoch 1:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1898/2223 [01:48<00:18, 17.20it/s]\u001b[A\nSTL Epoch 1:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1900/2223 [01:48<00:18, 17.77it/s]\u001b[A\nSTL Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1902/2223 [01:48<00:17, 18.15it/s]\u001b[A\nSTL Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1904/2223 [01:49<00:19, 16.69it/s]\u001b[A\nSTL Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1906/2223 [01:49<00:18, 16.98it/s]\u001b[A\nSTL Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1908/2223 [01:49<00:17, 17.61it/s]\u001b[A\nSTL Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1910/2223 [01:49<00:17, 18.12it/s]\u001b[A\nSTL Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1912/2223 [01:49<00:18, 16.77it/s]\u001b[A\nSTL Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1914/2223 [01:49<00:17, 17.25it/s]\u001b[A\nSTL Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1916/2223 [01:49<00:17, 17.77it/s]\u001b[A\nSTL Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1918/2223 [01:49<00:16, 18.08it/s]\u001b[A\nSTL Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1920/2223 [01:49<00:18, 16.70it/s]\u001b[A\nSTL Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1922/2223 [01:50<00:17, 17.19it/s]\u001b[A\nSTL Epoch 1:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1924/2223 [01:50<00:16, 17.67it/s]\u001b[A\nSTL Epoch 1:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1926/2223 [01:50<00:16, 18.11it/s]\u001b[A\nSTL Epoch 1:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1928/2223 [01:50<00:17, 16.67it/s]\u001b[A\nSTL Epoch 1:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1930/2223 [01:50<00:17, 17.13it/s]\u001b[A\nSTL Epoch 1:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1932/2223 [01:50<00:16, 17.69it/s]\u001b[A\nSTL Epoch 1:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1934/2223 [01:50<00:15, 18.19it/s]\u001b[A\nSTL Epoch 1:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1936/2223 [01:50<00:17, 16.84it/s]\u001b[A\nSTL Epoch 1:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1938/2223 [01:50<00:16, 17.28it/s]\u001b[A\nSTL Epoch 1:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1940/2223 [01:51<00:15, 17.79it/s]\u001b[A\nSTL Epoch 1:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1942/2223 [01:51<00:15, 18.08it/s]\u001b[A\nSTL Epoch 1:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1944/2223 [01:51<00:16, 16.77it/s]\u001b[A\nSTL Epoch 1:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1946/2223 [01:51<00:16, 17.26it/s]\u001b[A\nSTL Epoch 1:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1948/2223 [01:51<00:15, 17.81it/s]\u001b[A\nSTL Epoch 1:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1950/2223 [01:51<00:14, 18.22it/s]\u001b[A\nSTL Epoch 1:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1952/2223 [01:51<00:16, 16.83it/s]\u001b[A\nSTL Epoch 1:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1954/2223 [01:51<00:15, 17.25it/s]\u001b[A\nSTL Epoch 1:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1956/2223 [01:51<00:15, 17.76it/s]\u001b[A\nSTL Epoch 1:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1958/2223 [01:52<00:14, 18.18it/s]\u001b[A\nSTL Epoch 1:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1960/2223 [01:52<00:15, 16.82it/s]\u001b[A\nSTL Epoch 1:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1962/2223 [01:52<00:15, 17.31it/s]\u001b[A\nSTL Epoch 1:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1964/2223 [01:52<00:14, 17.85it/s]\u001b[A\nSTL Epoch 1:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1966/2223 [01:52<00:14, 17.97it/s]\u001b[A\nSTL Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1968/2223 [01:52<00:15, 16.58it/s]\u001b[A\nSTL Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1970/2223 [01:52<00:14, 17.05it/s]\u001b[A\nSTL Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1972/2223 [01:52<00:14, 17.65it/s]\u001b[A\nSTL Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1974/2223 [01:53<00:13, 18.06it/s]\u001b[A\nSTL Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1976/2223 [01:53<00:14, 16.69it/s]\u001b[A\nSTL Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1978/2223 [01:53<00:14, 17.04it/s]\u001b[A\nSTL Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1980/2223 [01:53<00:13, 17.59it/s]\u001b[A\nSTL Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1982/2223 [01:53<00:13, 18.07it/s]\u001b[A\nSTL Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1984/2223 [01:53<00:14, 16.76it/s]\u001b[A\nSTL Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1986/2223 [01:53<00:13, 17.20it/s]\u001b[A\nSTL Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1988/2223 [01:53<00:13, 17.76it/s]\u001b[A\nSTL Epoch 1:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1990/2223 [01:53<00:12, 18.22it/s]\u001b[A\nSTL Epoch 1:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1992/2223 [01:54<00:13, 16.73it/s]\u001b[A\nSTL Epoch 1:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1994/2223 [01:54<00:13, 17.12it/s]\u001b[A\nSTL Epoch 1:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1996/2223 [01:54<00:12, 17.48it/s]\u001b[A\nSTL Epoch 1:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1998/2223 [01:54<00:12, 17.72it/s]\u001b[A\nSTL Epoch 1:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 2000/2223 [01:54<00:13, 16.47it/s]\u001b[A\nSTL Epoch 1:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2002/2223 [01:54<00:13, 16.84it/s]\u001b[A\nSTL Epoch 1:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2004/2223 [01:54<00:12, 17.35it/s]\u001b[A\nSTL Epoch 1:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2006/2223 [01:54<00:12, 17.83it/s]\u001b[A\nSTL Epoch 1:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2008/2223 [01:55<00:13, 16.53it/s]\u001b[A\nSTL Epoch 1:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2010/2223 [01:55<00:12, 16.91it/s]\u001b[A\nSTL Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2012/2223 [01:55<00:12, 17.51it/s]\u001b[A\nSTL Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2014/2223 [01:55<00:11, 18.00it/s]\u001b[A\nSTL Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2016/2223 [01:55<00:12, 16.63it/s]\u001b[A\nSTL Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2018/2223 [01:55<00:11, 17.16it/s]\u001b[A\nSTL Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2020/2223 [01:55<00:11, 17.73it/s]\u001b[A\nSTL Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2022/2223 [01:55<00:11, 18.16it/s]\u001b[A\nSTL Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2024/2223 [01:55<00:11, 16.81it/s]\u001b[A\nSTL Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2026/2223 [01:56<00:11, 17.25it/s]\u001b[A\nSTL Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2028/2223 [01:56<00:10, 17.79it/s]\u001b[A\nSTL Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2030/2223 [01:56<00:10, 18.22it/s]\u001b[A\nSTL Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2032/2223 [01:56<00:11, 16.77it/s]\u001b[A\nSTL Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2034/2223 [01:56<00:10, 17.22it/s]\u001b[A\nSTL Epoch 1:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2036/2223 [01:56<00:10, 17.79it/s]\u001b[A\nSTL Epoch 1:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2038/2223 [01:56<00:10, 18.22it/s]\u001b[A\nSTL Epoch 1:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2040/2223 [01:56<00:10, 16.89it/s]\u001b[A\nSTL Epoch 1:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2042/2223 [01:56<00:10, 17.32it/s]\u001b[A\nSTL Epoch 1:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2044/2223 [01:57<00:10, 17.84it/s]\u001b[A\nSTL Epoch 1:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2046/2223 [01:57<00:09, 18.22it/s]\u001b[A\nSTL Epoch 1:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2048/2223 [01:57<00:10, 16.78it/s]\u001b[A\nSTL Epoch 1:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2050/2223 [01:57<00:10, 17.21it/s]\u001b[A\nSTL Epoch 1:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2052/2223 [01:57<00:09, 17.79it/s]\u001b[A\nSTL Epoch 1:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2054/2223 [01:57<00:09, 18.24it/s]\u001b[A\nSTL Epoch 1:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2056/2223 [01:57<00:09, 16.86it/s]\u001b[A\nSTL Epoch 1:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2058/2223 [01:57<00:09, 17.35it/s]\u001b[A\nSTL Epoch 1:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2060/2223 [01:57<00:09, 17.88it/s]\u001b[A\nSTL Epoch 1:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2062/2223 [01:58<00:08, 18.28it/s]\u001b[A\nSTL Epoch 1:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2064/2223 [01:58<00:09, 16.81it/s]\u001b[A\nSTL Epoch 1:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2066/2223 [01:58<00:09, 17.19it/s]\u001b[A\nSTL Epoch 1:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2068/2223 [01:58<00:08, 17.71it/s]\u001b[A\nSTL Epoch 1:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2070/2223 [01:58<00:08, 18.17it/s]\u001b[A\nSTL Epoch 1:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2072/2223 [01:58<00:08, 16.84it/s]\u001b[A\nSTL Epoch 1:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2074/2223 [01:58<00:08, 17.26it/s]\u001b[A\nSTL Epoch 1:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2076/2223 [01:58<00:08, 17.86it/s]\u001b[A\nSTL Epoch 1:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2078/2223 [01:58<00:07, 18.29it/s]\u001b[A\nSTL Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2080/2223 [01:59<00:08, 16.86it/s]\u001b[A\nSTL Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2082/2223 [01:59<00:08, 17.33it/s]\u001b[A\nSTL Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2084/2223 [01:59<00:07, 17.81it/s]\u001b[A\nSTL Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2086/2223 [01:59<00:07, 18.27it/s]\u001b[A\nSTL Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2088/2223 [01:59<00:07, 16.92it/s]\u001b[A\nSTL Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2090/2223 [01:59<00:07, 17.39it/s]\u001b[A\nSTL Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2092/2223 [01:59<00:07, 17.93it/s]\u001b[A\nSTL Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2094/2223 [01:59<00:07, 18.35it/s]\u001b[A\nSTL Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2096/2223 [02:00<00:07, 16.91it/s]\u001b[A\nSTL Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2098/2223 [02:00<00:07, 17.29it/s]\u001b[A\nSTL Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2100/2223 [02:00<00:06, 17.83it/s]\u001b[A\nSTL Epoch 1:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2102/2223 [02:00<00:06, 18.18it/s]\u001b[A\nSTL Epoch 1:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2104/2223 [02:00<00:07, 16.80it/s]\u001b[A\nSTL Epoch 1:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2106/2223 [02:00<00:06, 17.29it/s]\u001b[A\nSTL Epoch 1:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2108/2223 [02:00<00:06, 17.83it/s]\u001b[A\nSTL Epoch 1:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2110/2223 [02:00<00:06, 18.34it/s]\u001b[A\nSTL Epoch 1:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2112/2223 [02:00<00:06, 16.96it/s]\u001b[A\nSTL Epoch 1:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2114/2223 [02:01<00:06, 17.36it/s]\u001b[A\nSTL Epoch 1:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2116/2223 [02:01<00:05, 17.94it/s]\u001b[A\nSTL Epoch 1:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2118/2223 [02:01<00:05, 18.34it/s]\u001b[A\nSTL Epoch 1:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2120/2223 [02:01<00:06, 16.85it/s]\u001b[A\nSTL Epoch 1:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2122/2223 [02:01<00:05, 17.30it/s]\u001b[A\nSTL Epoch 1:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2124/2223 [02:01<00:05, 17.85it/s]\u001b[A\nSTL Epoch 1:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2126/2223 [02:01<00:05, 18.32it/s]\u001b[A\nSTL Epoch 1:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2128/2223 [02:01<00:05, 16.95it/s]\u001b[A\nSTL Epoch 1:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2130/2223 [02:01<00:05, 17.39it/s]\u001b[A\nSTL Epoch 1:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2132/2223 [02:02<00:05, 17.94it/s]\u001b[A\nSTL Epoch 1:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2134/2223 [02:02<00:04, 18.29it/s]\u001b[A\nSTL Epoch 1:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2136/2223 [02:02<00:05, 16.93it/s]\u001b[A\nSTL Epoch 1:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2138/2223 [02:02<00:04, 17.33it/s]\u001b[A\nSTL Epoch 1:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2140/2223 [02:02<00:04, 17.82it/s]\u001b[A\nSTL Epoch 1:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2142/2223 [02:02<00:04, 18.22it/s]\u001b[A\nSTL Epoch 1:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2144/2223 [02:02<00:04, 16.13it/s]\u001b[A\nSTL Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2146/2223 [02:02<00:04, 16.75it/s]\u001b[A\nSTL Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2148/2223 [02:02<00:04, 17.47it/s]\u001b[A\nSTL Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2150/2223 [02:03<00:04, 17.12it/s]\u001b[A\nSTL Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2152/2223 [02:03<00:04, 16.19it/s]\u001b[A\nSTL Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2154/2223 [02:03<00:04, 16.70it/s]\u001b[A\nSTL Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2156/2223 [02:03<00:03, 17.14it/s]\u001b[A\nSTL Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2158/2223 [02:03<00:03, 17.66it/s]\u001b[A\nSTL Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2160/2223 [02:03<00:03, 16.53it/s]\u001b[A\nSTL Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2162/2223 [02:03<00:03, 17.04it/s]\u001b[A\nSTL Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2164/2223 [02:03<00:03, 17.65it/s]\u001b[A\nSTL Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2166/2223 [02:04<00:03, 18.11it/s]\u001b[A\nSTL Epoch 1:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2168/2223 [02:04<00:03, 16.44it/s]\u001b[A\nSTL Epoch 1:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2170/2223 [02:04<00:03, 16.60it/s]\u001b[A\nSTL Epoch 1:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2172/2223 [02:04<00:02, 17.36it/s]\u001b[A\nSTL Epoch 1:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2174/2223 [02:04<00:02, 17.86it/s]\u001b[A\nSTL Epoch 1:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2176/2223 [02:04<00:02, 16.60it/s]\u001b[A\nSTL Epoch 1:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2178/2223 [02:04<00:02, 17.03it/s]\u001b[A\nSTL Epoch 1:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2180/2223 [02:04<00:02, 17.69it/s]\u001b[A\nSTL Epoch 1:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2182/2223 [02:04<00:02, 18.20it/s]\u001b[A\nSTL Epoch 1:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2184/2223 [02:05<00:02, 16.76it/s]\u001b[A\nSTL Epoch 1:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2186/2223 [02:05<00:02, 17.17it/s]\u001b[A\nSTL Epoch 1:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2188/2223 [02:05<00:01, 17.75it/s]\u001b[A\nSTL Epoch 1:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2190/2223 [02:05<00:01, 18.18it/s]\u001b[A\nSTL Epoch 1:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2192/2223 [02:05<00:01, 16.81it/s]\u001b[A\nSTL Epoch 1:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2194/2223 [02:05<00:01, 17.25it/s]\u001b[A\nSTL Epoch 1:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2196/2223 [02:05<00:01, 17.84it/s]\u001b[A\nSTL Epoch 1:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2198/2223 [02:05<00:01, 18.33it/s]\u001b[A\nSTL Epoch 1:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2200/2223 [02:06<00:01, 16.94it/s]\u001b[A\nSTL Epoch 1:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2202/2223 [02:06<00:01, 17.36it/s]\u001b[A\nSTL Epoch 1:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2204/2223 [02:06<00:01, 17.92it/s]\u001b[A\nSTL Epoch 1:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2206/2223 [02:06<00:00, 18.33it/s]\u001b[A\nSTL Epoch 1:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2208/2223 [02:06<00:00, 16.84it/s]\u001b[A\nSTL Epoch 1:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2210/2223 [02:06<00:00, 17.29it/s]\u001b[A\nSTL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2212/2223 [02:06<00:00, 17.84it/s]\u001b[A\nSTL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2214/2223 [02:06<00:00, 18.32it/s]\u001b[A\nSTL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2216/2223 [02:06<00:00, 16.99it/s]\u001b[A\nSTL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2218/2223 [02:07<00:00, 17.34it/s]\u001b[A\nSTL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2220/2223 [02:07<00:00, 17.86it/s]\u001b[A\nSTL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2223/2223 [02:07<00:00, 17.47it/s]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"    Epoch 1 Average Loss: 0.9106\n  ‚úÖ STL stayingpower: Accuracy=0.635, F1=0.581\n\nüìà STL Training: texture\n","output_type":"stream"},{"name":"stderr","text":"STL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3909/3909 [03:40<00:00, 17.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"    Epoch 1 Average Loss: 0.7519\n  ‚úÖ STL texture: Accuracy=0.724, F1=0.656\n\nüìà STL Training: smell\n","output_type":"stream"},{"name":"stderr","text":"STL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2328/2328 [02:10<00:00, 17.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"    Epoch 1 Average Loss: 0.5239\n  ‚úÖ STL smell: Accuracy=0.804, F1=0.717\n\nüìà STL Training: price\n","output_type":"stream"},{"name":"stderr","text":"STL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2628/2628 [02:27<00:00, 17.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"    Epoch 1 Average Loss: 0.0921\n  ‚úÖ STL price: Accuracy=0.985, F1=0.977\n\nüìà STL Training: colour\n","output_type":"stream"},{"name":"stderr","text":"STL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6015/6015 [05:37<00:00, 17.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"    Epoch 1 Average Loss: 0.5566\n  ‚úÖ STL colour: Accuracy=0.840, F1=0.767\n\nüìà STL Training: shipping\n","output_type":"stream"},{"name":"stderr","text":"STL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4375/4375 [04:07<00:00, 17.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"    Epoch 1 Average Loss: 0.4995\n  ‚úÖ STL shipping: Accuracy=0.858, F1=0.830\n\nüìà STL Training: packing\n","output_type":"stream"},{"name":"stderr","text":"STL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2441/2441 [02:18<00:00, 17.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"    Epoch 1 Average Loss: 0.1954\n  ‚úÖ STL packing: Accuracy=0.961, F1=0.941\nüíæ GPU Memory before MTL: 0.02GB\n\nü§ù TRAINING MTL MODEL for COSMETIC\n============================================================\n  üìä MTL Training: 13260 samples, 7 aspects\n","output_type":"stream"},{"name":"stderr","text":"MTL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10608/10608 [10:17<00:00, 17.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"    Epoch 1 Average Loss: nan\n  ‚úÖ MTL stayingpower: Accuracy=0.542, F1=0.381\n  ‚úÖ MTL texture: Accuracy=0.705, F1=0.583\n  ‚úÖ MTL smell: Accuracy=0.816, F1=0.734\n  ‚úÖ MTL price: Accuracy=0.978, F1=0.967\n  ‚úÖ MTL colour: Accuracy=0.828, F1=0.750\n  ‚úÖ MTL shipping: Accuracy=0.664, F1=0.529\n  ‚úÖ MTL packing: Accuracy=0.965, F1=0.948\n\n================================================================================\nüîÑ TRAINING HOTEL MODELS\n================================================================================\nüíæ GPU Memory before STL: 0.02GB\n\nüéØ TRAINING STL MODELS for HOTEL\n============================================================\n\nüìà STL Training: FACILITIES#DESIGN&FEATURES\n","output_type":"stream"},{"name":"stderr","text":"STL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 596/596 [00:34<00:00, 17.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"    Epoch 1 Average Loss: 0.7776\n  ‚úÖ STL FACILITIES#DESIGN&FEATURES: Accuracy=0.779, F1=0.761\n\nüìà STL Training: FACILITIES#GENERAL\n","output_type":"stream"},{"name":"stderr","text":"STL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 224/224 [00:12<00:00, 17.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"    Epoch 1 Average Loss: 0.5373\n  ‚úÖ STL FACILITIES#GENERAL: Accuracy=0.860, F1=0.795\nüíæ GPU Memory before MTL: 0.02GB\n\nü§ù TRAINING MTL MODEL for HOTEL\n============================================================\n  üìä MTL Training: 954 samples, 2 aspects\n","output_type":"stream"},{"name":"stderr","text":"MTL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 763/763 [00:43<00:00, 17.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"    Epoch 1 Average Loss: nan\n  ‚úÖ MTL FACILITIES#DESIGN&FEATURES: Accuracy=0.667, F1=0.636\n  ‚úÖ MTL FACILITIES#GENERAL: Accuracy=0.841, F1=0.769\n\n================================================================================\nüîÑ TRAINING RESTAURANT MODELS\n================================================================================\nüíæ GPU Memory before STL: 0.02GB\n\nüéØ TRAINING STL MODELS for RESTAURANT\n============================================================\n\nüìà STL Training: AMBIENCE#GENERAL\n","output_type":"stream"},{"name":"stderr","text":"STL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 753/753 [00:42<00:00, 17.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"    Epoch 1 Average Loss: 0.8274\n  ‚úÖ STL AMBIENCE#GENERAL: Accuracy=0.704, F1=0.581\n\nüìà STL Training: DRINKS#PRICES\n","output_type":"stream"},{"name":"stderr","text":"STL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 116/116 [00:06<00:00, 17.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"    Epoch 1 Average Loss: 0.9482\n  ‚úÖ STL DRINKS#PRICES: Accuracy=0.600, F1=0.450\n\nüìà STL Training: DRINKS#QUALITY\n","output_type":"stream"},{"name":"stderr","text":"STL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 122/122 [00:06<00:00, 17.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"    Epoch 1 Average Loss: 0.7021\n  ‚úÖ STL DRINKS#QUALITY: Accuracy=0.806, F1=0.720\n\nüìà STL Training: DRINKS#STYLE&OPTIONS\n","output_type":"stream"},{"name":"stderr","text":"STL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [00:05<00:00, 17.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"    Epoch 1 Average Loss: 0.4501\n  ‚úÖ STL DRINKS#STYLE&OPTIONS: Accuracy=0.913, F1=0.872\n\nüìà STL Training: FOOD#PRICES\n","output_type":"stream"},{"name":"stderr","text":"STL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1700/1700 [01:36<00:00, 17.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"    Epoch 1 Average Loss: 0.8656\n  ‚úÖ STL FOOD#PRICES: Accuracy=0.784, F1=0.790\nüíæ GPU Memory before MTL: 0.02GB\n\nü§ù TRAINING MTL MODEL for RESTAURANT\n============================================================\n  üìä MTL Training: 2601 samples, 5 aspects\n","output_type":"stream"},{"name":"stderr","text":"MTL Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2080/2080 [01:59<00:00, 17.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"    Epoch 1 Average Loss: nan\n  ‚úÖ MTL AMBIENCE#GENERAL: Accuracy=0.678, F1=0.554\n  ‚úÖ MTL DRINKS#PRICES: Accuracy=0.455, F1=0.284\n  ‚úÖ MTL DRINKS#QUALITY: Accuracy=0.767, F1=0.666\n  ‚úÖ MTL DRINKS#STYLE&OPTIONS: Accuracy=0.871, F1=0.811\n  ‚úÖ MTL FOOD#PRICES: Accuracy=0.724, F1=0.696\n\n================================================================================\nüìä COMPREHENSIVE STL vs MTL COMPARISON\n================================================================================\n\nüè¢ COSMETIC DOMAIN:\n--------------------------------------------------\n  stayingpower:\n    STL: Acc=0.635, F1=0.581\n    MTL: Acc=0.542, F1=0.381\n    Diff: Acc=-0.093, F1=-0.199\n  texture:\n    STL: Acc=0.724, F1=0.656\n    MTL: Acc=0.705, F1=0.583\n    Diff: Acc=-0.019, F1=-0.073\n  smell:\n    STL: Acc=0.804, F1=0.717\n    MTL: Acc=0.816, F1=0.734\n    Diff: Acc=+0.012, F1=+0.016\n  price:\n    STL: Acc=0.985, F1=0.977\n    MTL: Acc=0.978, F1=0.967\n    Diff: Acc=-0.007, F1=-0.010\n  colour:\n    STL: Acc=0.840, F1=0.767\n    MTL: Acc=0.828, F1=0.750\n    Diff: Acc=-0.012, F1=-0.017\n  shipping:\n    STL: Acc=0.858, F1=0.830\n    MTL: Acc=0.664, F1=0.529\n    Diff: Acc=-0.195, F1=-0.301\n  packing:\n    STL: Acc=0.961, F1=0.941\n    MTL: Acc=0.965, F1=0.948\n    Diff: Acc=+0.005, F1=+0.007\n\n  üìà DOMAIN AVERAGE:\n    STL: Acc=0.830, F1=0.781\n    MTL: Acc=0.785, F1=0.699\n    MTL Improvement: Acc=-0.044, F1=-0.083\n\nüè¢ HOTEL DOMAIN:\n--------------------------------------------------\n  FACILITIES#DESIGN&FEATURES:\n    STL: Acc=0.779, F1=0.761\n    MTL: Acc=0.667, F1=0.636\n    Diff: Acc=-0.112, F1=-0.125\n  FACILITIES#GENERAL:\n    STL: Acc=0.860, F1=0.795\n    MTL: Acc=0.841, F1=0.769\n    Diff: Acc=-0.018, F1=-0.026\n\n  üìà DOMAIN AVERAGE:\n    STL: Acc=0.819, F1=0.778\n    MTL: Acc=0.754, F1=0.702\n    MTL Improvement: Acc=-0.065, F1=-0.076\n\nüè¢ RESTAURANT DOMAIN:\n--------------------------------------------------\n  AMBIENCE#GENERAL:\n    STL: Acc=0.704, F1=0.581\n    MTL: Acc=0.678, F1=0.554\n    Diff: Acc=-0.026, F1=-0.027\n  DRINKS#PRICES:\n    STL: Acc=0.600, F1=0.450\n    MTL: Acc=0.455, F1=0.284\n    Diff: Acc=-0.145, F1=-0.166\n  DRINKS#QUALITY:\n    STL: Acc=0.806, F1=0.720\n    MTL: Acc=0.767, F1=0.666\n    Diff: Acc=-0.039, F1=-0.054\n  DRINKS#STYLE&OPTIONS:\n    STL: Acc=0.913, F1=0.872\n    MTL: Acc=0.871, F1=0.811\n    Diff: Acc=-0.042, F1=-0.061\n  FOOD#PRICES:\n    STL: Acc=0.784, F1=0.790\n    MTL: Acc=0.724, F1=0.696\n    Diff: Acc=-0.060, F1=-0.094\n\n  üìà DOMAIN AVERAGE:\n    STL: Acc=0.761, F1=0.683\n    MTL: Acc=0.699, F1=0.602\n    MTL Improvement: Acc=-0.062, F1=-0.080\n\nüîç KEY INSIGHTS:\n  üéØ STL: M·ªói aspect c√≥ model ri√™ng bi·ªát\n  ü§ù MTL: M·ªôt model chia s·∫ª cho t·∫•t c·∫£ aspects\n  üí° MTL c√≥ th·ªÉ t·∫≠n d·ª•ng shared knowledge gi·ªØa aspects\n  ‚ö° STL c√≥ th·ªÉ t·∫≠p trung t·ªët h∆°n cho t·ª´ng aspect c·ª• th·ªÉ\n\n‚úÖ STL vs MTL Comparison Complete!\n","output_type":"stream"}],"execution_count":2}]}